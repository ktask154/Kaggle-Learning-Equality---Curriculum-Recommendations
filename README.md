# Kaggle-Learning-Equality---Curriculum-Recommendations

[link](https://www.kaggle.com/competitions/learning-equality-curriculum-recommendations)

# Task
å¤šè¨€èªã®æ•™è‚²å†…å®¹ã®ã‚«ãƒªã‚­ãƒ¥ãƒ©ãƒ ã‚’ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ã¨ä¸€è‡´ã•ã›ã‚‹ã€‚ [link](https://www.youtube.com/watch?v=6tq3tGihQhY)

<br />

### è©•ä¾¡é–¢æ•°
F2 score

<br />

## Models
- stsb-xlm-r-multilingual (First Stage)

- paraphrase-multilingual-mpnet-base-v2 (Second Stage)

<br />

## Main methods that worked
![å…¨ä½“åƒ](img/work.png "å…¨ä½“åƒ")

- First Stage
  - step1 : Finetuning Language Model
    - epoch : 20
    - batch_size : 64
    - MultipleNegativesRankingLoss
  - step2 : Clustering Unsupervised train set
    - K-Top : 50
- Second Stage
   - step3 : ReRanking
   - step4 : Inference
   
 

<br />

## Final Result

103 / 1057 ä½  ğŸ¥‰

CV : 0.6107

Public LB : 0.54146

Private LB : 0.55678


<br />
<br />

## Efficiency Prize

## Work

- First Stage ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã¾ã§ã®çŠ¶æ…‹ã§æå‡º
  - model : all-MiniLM-L6-v2
  - K-Top : 5
 
## Result

21 ä½

CV : 0.3458

Private LB : 0.33418

Scoring Time : 	2391

EfficiencyScore : -0.363328

