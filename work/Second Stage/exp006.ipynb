{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23297,"status":"ok","timestamp":1678196561408,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wH5JjZwrcfCs","outputId":"c6176320-3cab-411a-a194-b1e9cc744c1b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21027,"status":"ok","timestamp":1678196582432,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"_6ZHzRZycrfI","outputId":"c54931e5-984d-480b-92e2-09795d5179d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/469.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/469.0 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 KB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.22.4)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.4)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (3.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, dill, responses, multiprocess, huggingface-hub, datasets\n","Successfully installed datasets-2.10.1 dill-0.3.6 huggingface-hub-0.12.1 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.97\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.21.2\n","  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (2.25.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.21.2) (1.22.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.21.2) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (2022.12.7)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.21.2) (1.26.14)\n","Installing collected packages: tokenizers, transformers\n","Successfully installed tokenizers-0.12.1 transformers-4.21.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers==0.12.1 in /usr/local/lib/python3.8/dist-packages (0.12.1)\n"]}],"source":["!pip install datasets\n","!pip install sentencepiece\n","!pip install transformers==4.21.2\n","!pip install tokenizers==0.12.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1063,"status":"ok","timestamp":1678196583490,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"JuE_30dQctgr","outputId":"a1c11859-cc81-4f5d-a61a-fa47f7de6bf7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Mar  7 13:43:01 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gv-kr0Wcv9_"},"outputs":[],"source":["import os\n","\n","DIR = \"/content/drive/MyDrive/Competitions/Kaggle/LECR\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","OUTPUT_FINETUNE = os.path.join(OUTPUT_DIR,\"FINETUNE\")\n","OUTPUT_MODELS = os.path.join(OUTPUT_DIR,\"OUTPUT_MODELS\")\n","OUTPUT_MODELS_EXP = os.path.join(OUTPUT_MODELS,\"EXP006\")\n","USE_MODEL_DIR = os.path.join(OUTPUT_FINETUNE,\"003_paraphrase-multilingual-mpnet-base-v2\")\n","CUSTOM_MODEL_DIR = os.path.join(USE_MODEL_DIR,\"paraphrase-multilingual-mpnet-base-v2_fold0_epochs20\")\n","\n","if not os.path.exists(OUTPUT_FINETUNE):\n","    os.makedirs(OUTPUT_FINETUNE)\n","\n","if not os.path.exists(OUTPUT_MODELS):\n","    os.makedirs(OUTPUT_MODELS)\n","\n","if not os.path.exists(OUTPUT_MODELS_EXP):\n","    os.makedirs(OUTPUT_MODELS_EXP)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7057,"status":"ok","timestamp":1678196592353,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"Q-g7lqAoebII","outputId":"3c41c9a2-8b39-4fc5-a46c-71f0d6ebed8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# =========================================================================================\n","# Libraries\n","# =========================================================================================\n","import gc\n","import time\n","import math\n","import random\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import numpy as np\n","import pandas as pd\n","from tqdm.auto import tqdm\n","import torch\n","import torch.nn as nn\n","from torch.optim import AdamW\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.checkpoint import checkpoint\n","import tokenizers\n","import transformers\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_cosine_schedule_with_warmup, DataCollatorWithPadding\n","from sklearn.model_selection import StratifiedGroupKFold, KFold\n","%env TOKENIZERS_PARALLELISM=true\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfwH8QEZejO6"},"outputs":[],"source":["# =========================================================================================\n","# Configurations\n","# =========================================================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq = 500\n","    num_workers = 4\n","    model = CUSTOM_MODEL_DIR\n","    model_name = \"multilingual-mpnet-base-v2\"\n","    gradient_checkpointing = False\n","    scheduler='cosine' # ['linear', 'cosine','polynomial']\n","    batch_scheduler=True\n","    num_cycles = 0.5\n","    warmup_ratio = 0.1\n","    epochs = 3\n","    encoder_lr = 1e-5\n","    decoder_lr = 1e-4\n","    eps = 1e-6\n","    betas = (0.9, 0.999)\n","    batch_size = 32\n","    weight_decay = 0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm = 0.012\n","    target_size=1\n","    target_cols='target'\n","    max_len = 512\n","    n_folds = 5\n","    seed = 42\n","    trn_fold=[0]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-hHBK3ChaiL"},"outputs":[],"source":["# =========================================================================================\n","# Seed everything for deterministic results\n","# =========================================================================================\n","def seed_everything(cfg):\n","    random.seed(cfg.seed)\n","    os.environ['PYTHONHASHSEED'] = str(cfg.seed)\n","    np.random.seed(cfg.seed)\n","    torch.manual_seed(cfg.seed)\n","    torch.cuda.manual_seed(cfg.seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(CFG)\n","    \n","    \n","def get_logger(filename=OUTPUT_MODELS_EXP+'/train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXwcjNdhhpm3"},"outputs":[],"source":["# =========================================================================================\n","# F2 score metric\n","# =========================================================================================\n","def f2_score(y_true, y_pred):\n","    y_true = y_true.apply(lambda x: set(x.split()))\n","    y_pred = y_pred.apply(lambda x: set(x.split()))\n","    tp = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n","    fp = np.array([len(x[1] - x[0]) for x in zip(y_true, y_pred)])\n","    fn = np.array([len(x[0] - x[1]) for x in zip(y_true, y_pred)])\n","    precision = tp / (tp + fp)\n","    recall = tp / (tp + fn)\n","    f2 = tp / (tp + 0.2 * fp + 0.8 * fn)\n","    return round(f2.mean(), 4)\n","\n","\n","\n","# =========================================================================================\n","# Get best threshold\n","# =========================================================================================\n","def get_best_threshold(x_val, val_predictions, correlations):\n","    best_score = 0\n","    best_threshold = None\n","    for thres in np.arange(0.001, 0.1, 0.001):\n","        x_val['predictions'] = np.where(val_predictions > thres, 1, 0)\n","        x_val1 = x_val[x_val['predictions'] == 1]\n","        x_val1 = x_val1.groupby(['topics_ids'])['content_ids'].unique().reset_index()\n","        x_val1['content_ids'] = x_val1['content_ids'].apply(lambda x: ' '.join(x))\n","        x_val1.columns = ['topic_id', 'predictions']\n","        x_val0 = pd.Series(x_val['topics_ids'].unique())\n","        x_val0 = x_val0[~x_val0.isin(x_val1['topic_id'])]\n","        x_val0 = pd.DataFrame({'topic_id': x_val0.values, 'predictions': \"\"})\n","        x_val_r = pd.concat([x_val1, x_val0], axis = 0, ignore_index = True)\n","        x_val_r = x_val_r.merge(correlations, how = 'left', on = 'topic_id')\n","        score = f2_score(x_val_r['content_ids'], x_val_r['predictions'])\n","        if score > best_score:\n","            best_score = score\n","            best_threshold = thres\n","    return best_score, best_threshold"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":455},"executionInfo":{"elapsed":156525,"status":"ok","timestamp":1678196748868,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"VfiJW2i8hus5","outputId":"86555c7a-33d9-4933-f01a-bc694b16f84f"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \n","--------------------------------------------------\n","train.shape: (3088094, 9)\n","correlations.shape: (61517, 2)\n"]},{"data":{"text/html":["\n","  <div id=\"df-1da4dae6-6403-4fb1-8e5f-c807cbd42f35\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topics_ids</th>\n","      <th>content_ids</th>\n","      <th>title1</th>\n","      <th>title2</th>\n","      <th>topic_language</th>\n","      <th>content_language</th>\n","      <th>target</th>\n","      <th>fold</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>t_30dd476279c8</td>\n","      <td>c_3088e6cf9846</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","      <td>Addictive and Dangerous Drugs Part 2&lt;|=t_sep=|...</td>\n","      <td>en</td>\n","      <td>fil</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>t_30dd476279c8</td>\n","      <td>c_3f7e1fb5de50</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","      <td>HIV and drug therapy&lt;|=t_sep=|&gt;Description doe...</td>\n","      <td>en</td>\n","      <td>en</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>t_30dd476279c8</td>\n","      <td>c_459fb30269cf</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","      <td>Emergency Medicine Questions 1-5&lt;|=t_sep=|&gt;Des...</td>\n","      <td>en</td>\n","      <td>en</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Medicine&lt;|=t_sep=|&gt;Description does not existM...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1da4dae6-6403-4fb1-8e5f-c807cbd42f35')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1da4dae6-6403-4fb1-8e5f-c807cbd42f35 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1da4dae6-6403-4fb1-8e5f-c807cbd42f35');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       topics_ids     content_ids  \\\n","0  t_30dd476279c8  c_3088e6cf9846   \n","1  t_30dd476279c8  c_3f7e1fb5de50   \n","2  t_30dd476279c8  c_459fb30269cf   \n","\n","                                              title1  \\\n","0  Medicine<|=t_sep=|>Description does not existM...   \n","1  Medicine<|=t_sep=|>Description does not existM...   \n","2  Medicine<|=t_sep=|>Description does not existM...   \n","\n","                                              title2 topic_language  \\\n","0  Addictive and Dangerous Drugs Part 2<|=t_sep=|...             en   \n","1  HIV and drug therapy<|=t_sep=|>Description doe...             en   \n","2  Emergency Medicine Questions 1-5<|=t_sep=|>Des...             en   \n","\n","  content_language  target  fold  \\\n","0              fil       0     0   \n","1               en       0     0   \n","2               en       0     0   \n","\n","                                                text  \n","0  Medicine<|=t_sep=|>Description does not existM...  \n","1  Medicine<|=t_sep=|>Description does not existM...  \n","2  Medicine<|=t_sep=|>Description does not existM...  "]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-3962f289-6ce0-4fc3-91f1-e7e000e5dc55\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>topic_id</th>\n","      <th>content_ids</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>t_00004da3a1b2</td>\n","      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>t_00068291e9a4</td>\n","      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>t_00069b63a70a</td>\n","      <td>c_11a1dc0bfb99</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3962f289-6ce0-4fc3-91f1-e7e000e5dc55')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3962f289-6ce0-4fc3-91f1-e7e000e5dc55 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3962f289-6ce0-4fc3-91f1-e7e000e5dc55');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["         topic_id                                        content_ids\n","0  t_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\n","1  t_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\n","2  t_00069b63a70a                                     c_11a1dc0bfb99"]},"metadata":{},"output_type":"display_data"}],"source":["# =========================================================================================\n","# Data Loading\n","# =========================================================================================\n","train = pd.read_csv('/content/drive/MyDrive/Competitions/Kaggle/LECR/input/xlm-roberta-base_train.csv')\n","train['title1'].fillna(\"Title does not exist\", inplace = True)\n","train['title2'].fillna(\"Title does not exist\", inplace = True)\n","correlations = pd.read_csv(os.path.join(INPUT_DIR,'correlations.csv'))\n","# Create feature column\n","train['text'] = train['title1'] + '[SEP]' + train['title2']\n","print(' ')\n","print('-' * 50)\n","print(f\"train.shape: {train.shape}\")\n","print(f\"correlations.shape: {correlations.shape}\")\n","display(train.head(3))\n","display(correlations.head(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1678196748868,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"uT7Qz5wviEkm","outputId":"78925954-7873-4155-d47e-27071b1c6718"},"outputs":[{"data":{"text/plain":["fold\n","0    615200\n","1    618306\n","2    618371\n","3    618601\n","4    617616\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["# =========================================================================================\n","# CV split\n","# =========================================================================================\n","train['fold'] = train['fold'].astype(int)\n","display(train.groupby('fold').size())\n","\n","\n","if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSv9OtqfiGyu"},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","#tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TyLbHXopiLbq"},"outputs":[],"source":["# =========================================================================================\n","# Get max length\n","# =========================================================================================\n","#lengths = []\n","#for text in tqdm(train['text'].fillna(\"\").values, total = len(train)):\n","#    length = len(CFG.tokenizer(text, add_special_tokens = False)['input_ids'])\n","#    lengths.append(length)\n","#CFG.max_len = max(lengths) + 3 # cls & sep\n","#print(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yxlOQyUoiN_M"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(text, cfg):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text, \n","        return_tensors = None, \n","        add_special_tokens = True, \n","        max_length = cfg.max_len,\n","        pad_to_max_length = True,\n","        truncation = True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype = torch.long)\n","    return inputs\n","\n","class custom_dataset(Dataset):\n","    def __init__(self, df, cfg):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.labels = df['target'].values\n","    def __len__(self):\n","        return len(self.texts)\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.texts[item], self.cfg)\n","        label = torch.tensor(self.labels[item], dtype = torch.float)\n","        return inputs, label\n","    \n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tK2bxkMiQJn"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","    \n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","    \n","class custom_model(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states = True)\n","            self.config.hidden_dropout = 0.0\n","            self.config.hidden_dropout_prob = 0.0\n","            self.config.attention_dropout = 0.0\n","            self.config.attention_probs_dropout_prob = 0.0\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config = self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","        #self.layer_norm1 = nn.LayerNorm(self.config.hidden_size,eps=1e-5)\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        #self._init_weights(self.layer_norm1)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","            \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_state = outputs.last_hidden_state\n","        feature = self.pool(last_hidden_state, inputs['attention_mask'])\n","        #feature = self.layer_norm1(feature)\n","        return feature\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ndChs3ZyiUt-"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s21-srBKiW8O"},"outputs":[],"source":["# =========================================================================================\n","# Train function loop\n","# =========================================================================================\n","def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled = cfg.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled = cfg.apex):\n","            y_preds = model(inputs)\n","            loss = criterion(y_preds.view(-1), labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / cfg.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n","        if (step + 1) % cfg.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % cfg.print_freq == 0 or step == (len(train_loader) - 1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch + 1, \n","                          step, \n","                          len(train_loader), \n","                          remain = timeSince(start, float(step + 1) / len(train_loader)),\n","                          loss = losses,\n","                          grad_norm = grad_norm,\n","                          lr = scheduler.get_lr()[0]))\n","    return losses.avg\n","\n","\n","\n","def valid_fn(valid_loader, model, criterion, device, cfg):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1), labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / cfg.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().squeeze().to('cpu').numpy().reshape(-1))\n","        end = time.time()\n","        if step % cfg.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    return losses.avg, predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUuAKDWNiZ-4"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, correlations, fold, cfg):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[cfg.target_cols].values\n","    \n","    train_dataset = custom_dataset(train_folds, cfg)\n","    valid_dataset = custom_dataset(valid_folds, cfg)\n","    \n","    train_loader = DataLoader(\n","        train_dataset, \n","        batch_size = cfg.batch_size, \n","        shuffle = True, \n","        num_workers = cfg.num_workers, \n","        pin_memory = True, \n","        drop_last = True\n","    )\n","    valid_loader = DataLoader(\n","        valid_dataset, \n","        batch_size = cfg.batch_size, \n","        shuffle = False, \n","        num_workers = cfg.num_workers, \n","        pin_memory = True, \n","        drop_last = False\n","    )\n","    \n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    \n","    model = custom_model(cfg, config_path=None, pretrained=True)\n","    torch.save(model.config, os.path.join(OUTPUT_MODELS_EXP,'config.pth'))\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr=5e-6, decoder_lr=1e-4, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n","        group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n","        group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n","        optimizer_parameters1 = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        optimizer_parameters2 = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters1\n","    \n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay\n","                                               )\n","    optimizer = AdamW(\n","        optimizer_parameters, \n","        lr = cfg.encoder_lr, \n","        eps = cfg.eps, \n","        betas = cfg.betas\n","    )\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps, num_warmup_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        elif cfg.scheduler == 'polynomial':\n","            scheduler = get_polynomial_decay_schedule_with_warmup(\n","                optimizer, warmup_steps, num_train_steps, lr_end=7e-7, power=3.0)\n","        return scheduler\n","    num_train_steps = int(len(train_folds) / cfg.batch_size * cfg.epochs)\n","    num_warmup_steps = num_train_steps * cfg.warmup_ratio\n","    scheduler = get_scheduler(cfg, optimizer, num_train_steps, num_warmup_steps)\n","    \n","    # Training & Validation loop\n","    criterion = nn.BCEWithLogitsLoss(reduction = \"mean\")\n","    \n","    best_score = 0\n","    for epoch in range(cfg.epochs):\n","        start_time = time.time()\n","        \n","        # Train\n","        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device, cfg)\n","        \n","        # Validation\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device, cfg)\n","        \n","        # Compute f2_score\n","        score, threshold = get_best_threshold(valid_folds, predictions, correlations)\n","        \n","        elapsed = time.time() - start_time\n","        print(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        print(f'Epoch {epoch+1} - Score: {score:.4f} - Threshold: {threshold:.5f}')\n","        \n","        if score > best_score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save(\n","                {'model': model.state_dict(), \n","                 'predictions': predictions}, \n","                os.path.join(OUTPUT_MODELS_EXP,f\"{cfg.model_name.replace('/', '-')}_fold{fold}_{cfg.seed}.pth\")\n","                )\n","            val_predictions = predictions\n","    preds = torch.load(os.path.join(OUTPUT_MODELS_EXP,f\"{cfg.model_name.replace('/', '-')}_fold{fold}_{cfg.seed}.pth\"), \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds[\"pred\"] = preds\n","    \n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    # Get best threshold\n","    best_score, best_threshold = get_best_threshold(valid_folds, val_predictions, correlations)\n","    print(f'Our CV score is {best_score} using a threshold of {best_threshold}')\n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYA47-OnidV9","outputId":"ac5958a4-66dc-4e0c-bc6b-949600085887"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","XLMRobertaConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/Kaggle/LECR/output/FINETUNE/003_paraphrase-multilingual-mpnet-base-v2/paraphrase-multilingual-mpnet-base-v2_fold0_epochs20\",\n","  \"architectures\": [\n","    \"XLMRobertaModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n","INFO:__main__:XLMRobertaConfig {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/Kaggle/LECR/output/FINETUNE/003_paraphrase-multilingual-mpnet-base-v2/paraphrase-multilingual-mpnet-base-v2_fold0_epochs20\",\n","  \"architectures\": [\n","    \"XLMRobertaModel\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"xlm-roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.21.2\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 250002\n","}\n","\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/77277] Elapsed 0m 5s (remain 6555m 47s) Loss: 0.6935(0.6935) Grad: 0.8778  LR: 0.00000000  \n","Epoch: [1][500/77277] Elapsed 1m 42s (remain 262m 32s) Loss: 0.6314(0.6731) Grad: 1.0341  LR: 0.00000022  \n","Epoch: [1][1000/77277] Elapsed 3m 20s (remain 254m 38s) Loss: 0.5010(0.6053) Grad: 0.6277  LR: 0.00000043  \n","Epoch: [1][1500/77277] Elapsed 4m 58s (remain 250m 57s) Loss: 0.2392(0.5106) Grad: 0.4787  LR: 0.00000065  \n","Epoch: [1][2000/77277] Elapsed 6m 35s (remain 248m 16s) Loss: 0.1692(0.4572) Grad: 0.5389  LR: 0.00000086  \n","Epoch: [1][2500/77277] Elapsed 8m 13s (remain 246m 4s) Loss: 0.2101(0.4275) Grad: 0.7639  LR: 0.00000108  \n","Epoch: [1][3000/77277] Elapsed 9m 51s (remain 243m 59s) Loss: 0.2379(0.4067) Grad: 0.5356  LR: 0.00000129  \n","Epoch: [1][3500/77277] Elapsed 11m 29s (remain 242m 3s) Loss: 0.2460(0.3917) Grad: 0.6882  LR: 0.00000151  \n","Epoch: [1][4000/77277] Elapsed 13m 6s (remain 240m 13s) Loss: 0.3883(0.3797) Grad: 1.1515  LR: 0.00000173  \n","Epoch: [1][4500/77277] Elapsed 14m 44s (remain 238m 25s) Loss: 0.3277(0.3705) Grad: 1.6486  LR: 0.00000194  \n","Epoch: [1][5000/77277] Elapsed 16m 22s (remain 236m 41s) Loss: 0.4467(0.3623) Grad: 1.6868  LR: 0.00000216  \n","Epoch: [1][5500/77277] Elapsed 18m 0s (remain 234m 57s) Loss: 0.2415(0.3562) Grad: 0.8375  LR: 0.00000237  \n","Epoch: [1][6000/77277] Elapsed 19m 38s (remain 233m 13s) Loss: 0.2006(0.3507) Grad: 0.8329  LR: 0.00000259  \n","Epoch: [1][6500/77277] Elapsed 21m 15s (remain 231m 30s) Loss: 0.1689(0.3461) Grad: 0.9175  LR: 0.00000280  \n","Epoch: [1][7000/77277] Elapsed 22m 53s (remain 229m 48s) Loss: 0.1874(0.3422) Grad: 1.1884  LR: 0.00000302  \n","Epoch: [1][7500/77277] Elapsed 24m 31s (remain 228m 7s) Loss: 0.3589(0.3389) Grad: 1.1365  LR: 0.00000324  \n","Epoch: [1][8000/77277] Elapsed 26m 9s (remain 226m 25s) Loss: 0.4753(0.3360) Grad: 2.2850  LR: 0.00000345  \n","Epoch: [1][8500/77277] Elapsed 27m 46s (remain 224m 46s) Loss: 0.1534(0.3332) Grad: 1.1889  LR: 0.00000367  \n","Epoch: [1][9000/77277] Elapsed 29m 24s (remain 223m 6s) Loss: 0.2384(0.3302) Grad: 1.0815  LR: 0.00000388  \n","Epoch: [1][9500/77277] Elapsed 31m 2s (remain 221m 25s) Loss: 0.1568(0.3276) Grad: 1.2275  LR: 0.00000410  \n","Epoch: [1][10000/77277] Elapsed 32m 40s (remain 219m 46s) Loss: 0.3571(0.3251) Grad: 1.3348  LR: 0.00000431  \n","Epoch: [1][10500/77277] Elapsed 34m 18s (remain 218m 7s) Loss: 0.2323(0.3230) Grad: 1.0052  LR: 0.00000453  \n","Epoch: [1][11000/77277] Elapsed 35m 55s (remain 216m 27s) Loss: 0.1477(0.3207) Grad: 1.1267  LR: 0.00000475  \n","Epoch: [1][11500/77277] Elapsed 37m 33s (remain 214m 47s) Loss: 0.5116(0.3187) Grad: 3.2360  LR: 0.00000496  \n","Epoch: [1][12000/77277] Elapsed 39m 11s (remain 213m 8s) Loss: 0.0916(0.3168) Grad: 1.5227  LR: 0.00000518  \n","Epoch: [1][12500/77277] Elapsed 40m 48s (remain 211m 29s) Loss: 0.1104(0.3148) Grad: 2.1943  LR: 0.00000539  \n","Epoch: [1][13000/77277] Elapsed 42m 26s (remain 209m 50s) Loss: 0.2357(0.3130) Grad: 1.5693  LR: 0.00000561  \n","Epoch: [1][13500/77277] Elapsed 44m 4s (remain 208m 11s) Loss: 0.3095(0.3115) Grad: 1.5440  LR: 0.00000582  \n","Epoch: [1][14000/77277] Elapsed 45m 41s (remain 206m 32s) Loss: 0.3272(0.3097) Grad: 2.4721  LR: 0.00000604  \n","Epoch: [1][14500/77277] Elapsed 47m 19s (remain 204m 52s) Loss: 0.2068(0.3081) Grad: 1.2129  LR: 0.00000625  \n","Epoch: [1][15000/77277] Elapsed 48m 57s (remain 203m 14s) Loss: 0.4688(0.3066) Grad: 2.4127  LR: 0.00000647  \n","Epoch: [1][15500/77277] Elapsed 50m 35s (remain 201m 35s) Loss: 0.4300(0.3052) Grad: 2.2711  LR: 0.00000669  \n","Epoch: [1][16000/77277] Elapsed 52m 12s (remain 199m 57s) Loss: 0.1497(0.3041) Grad: 1.5644  LR: 0.00000690  \n","Epoch: [1][16500/77277] Elapsed 53m 50s (remain 198m 18s) Loss: 0.3266(0.3025) Grad: 2.2162  LR: 0.00000712  \n","Epoch: [1][17000/77277] Elapsed 55m 28s (remain 196m 40s) Loss: 0.4147(0.3012) Grad: 2.8454  LR: 0.00000733  \n","Epoch: [1][17500/77277] Elapsed 57m 5s (remain 195m 1s) Loss: 0.4398(0.2999) Grad: 2.2755  LR: 0.00000755  \n","Epoch: [1][18000/77277] Elapsed 58m 43s (remain 193m 23s) Loss: 0.3818(0.2986) Grad: 3.7190  LR: 0.00000776  \n","Epoch: [1][18500/77277] Elapsed 60m 21s (remain 191m 44s) Loss: 0.3036(0.2975) Grad: 1.4937  LR: 0.00000798  \n","Epoch: [1][19000/77277] Elapsed 61m 59s (remain 190m 6s) Loss: 0.2300(0.2961) Grad: 2.4802  LR: 0.00000820  \n","Epoch: [1][19500/77277] Elapsed 63m 37s (remain 188m 28s) Loss: 0.5739(0.2950) Grad: 3.8528  LR: 0.00000841  \n","Epoch: [1][20000/77277] Elapsed 65m 14s (remain 186m 50s) Loss: 0.4247(0.2939) Grad: 3.9036  LR: 0.00000863  \n","Epoch: [1][20500/77277] Elapsed 66m 52s (remain 185m 12s) Loss: 0.1694(0.2927) Grad: 1.8955  LR: 0.00000884  \n","Epoch: [1][21000/77277] Elapsed 68m 30s (remain 183m 34s) Loss: 0.2643(0.2916) Grad: 6.0667  LR: 0.00000906  \n","Epoch: [1][21500/77277] Elapsed 70m 8s (remain 181m 56s) Loss: 0.1424(0.2904) Grad: 2.0581  LR: 0.00000927  \n","Epoch: [1][22000/77277] Elapsed 71m 45s (remain 180m 18s) Loss: 0.2854(0.2895) Grad: 2.4164  LR: 0.00000949  \n","Epoch: [1][22500/77277] Elapsed 73m 23s (remain 178m 40s) Loss: 0.0684(0.2884) Grad: 1.3768  LR: 0.00000971  \n","Epoch: [1][23000/77277] Elapsed 75m 1s (remain 177m 1s) Loss: 0.3887(0.2872) Grad: 1.9323  LR: 0.00000992  \n","Epoch: [1][23500/77277] Elapsed 76m 39s (remain 175m 23s) Loss: 0.3434(0.2863) Grad: 1.4832  LR: 0.00001000  \n","Epoch: [1][24000/77277] Elapsed 78m 16s (remain 173m 45s) Loss: 0.8216(0.2853) Grad: 4.7771  LR: 0.00001000  \n","Epoch: [1][24500/77277] Elapsed 79m 54s (remain 172m 7s) Loss: 0.2193(0.2842) Grad: 1.4555  LR: 0.00001000  \n","Epoch: [1][25000/77277] Elapsed 81m 32s (remain 170m 29s) Loss: 0.4447(0.2832) Grad: 4.1597  LR: 0.00001000  \n","Epoch: [1][25500/77277] Elapsed 83m 10s (remain 168m 51s) Loss: 0.2698(0.2825) Grad: 1.7126  LR: 0.00001000  \n","Epoch: [1][26000/77277] Elapsed 84m 47s (remain 167m 13s) Loss: 0.2693(0.2816) Grad: 2.4919  LR: 0.00001000  \n","Epoch: [1][26500/77277] Elapsed 86m 25s (remain 165m 35s) Loss: 0.1649(0.2806) Grad: 1.6014  LR: 0.00000999  \n","Epoch: [1][27000/77277] Elapsed 88m 3s (remain 163m 57s) Loss: 0.2590(0.2797) Grad: 2.1547  LR: 0.00000999  \n","Epoch: [1][27500/77277] Elapsed 89m 41s (remain 162m 19s) Loss: 0.1323(0.2787) Grad: 2.8364  LR: 0.00000999  \n","Epoch: [1][28000/77277] Elapsed 91m 18s (remain 160m 41s) Loss: 0.3955(0.2777) Grad: 2.2654  LR: 0.00000999  \n","Epoch: [1][28500/77277] Elapsed 92m 56s (remain 159m 4s) Loss: 0.3614(0.2768) Grad: 3.7336  LR: 0.00000998  \n","Epoch: [1][29000/77277] Elapsed 94m 34s (remain 157m 26s) Loss: 0.3127(0.2760) Grad: 2.4975  LR: 0.00000998  \n","Epoch: [1][29500/77277] Elapsed 96m 12s (remain 155m 48s) Loss: 0.4781(0.2752) Grad: 4.4106  LR: 0.00000998  \n","Epoch: [1][30000/77277] Elapsed 97m 50s (remain 154m 10s) Loss: 0.1554(0.2743) Grad: 1.6038  LR: 0.00000997  \n","Epoch: [1][30500/77277] Elapsed 99m 28s (remain 152m 32s) Loss: 0.4442(0.2735) Grad: 13.6008  LR: 0.00000997  \n","Epoch: [1][31000/77277] Elapsed 101m 5s (remain 150m 54s) Loss: 0.3317(0.2727) Grad: 2.3989  LR: 0.00000997  \n","Epoch: [1][31500/77277] Elapsed 102m 43s (remain 149m 16s) Loss: 0.2806(0.2720) Grad: 3.1186  LR: 0.00000996  \n","Epoch: [1][32000/77277] Elapsed 104m 21s (remain 147m 39s) Loss: 0.0876(0.2712) Grad: 2.0672  LR: 0.00000996  \n","Epoch: [1][32500/77277] Elapsed 105m 59s (remain 146m 1s) Loss: 0.3418(0.2703) Grad: 2.9451  LR: 0.00000995  \n","Epoch: [1][33000/77277] Elapsed 107m 37s (remain 144m 23s) Loss: 0.0556(0.2695) Grad: 1.2858  LR: 0.00000995  \n","Epoch: [1][33500/77277] Elapsed 109m 15s (remain 142m 45s) Loss: 0.1064(0.2688) Grad: 1.8481  LR: 0.00000994  \n","Epoch: [1][34000/77277] Elapsed 110m 52s (remain 141m 7s) Loss: 0.2169(0.2679) Grad: 2.4425  LR: 0.00000993  \n","Epoch: [1][34500/77277] Elapsed 112m 30s (remain 139m 29s) Loss: 0.2042(0.2671) Grad: 1.9099  LR: 0.00000993  \n","Epoch: [1][35000/77277] Elapsed 114m 8s (remain 137m 51s) Loss: 0.1236(0.2664) Grad: 1.8334  LR: 0.00000992  \n","Epoch: [1][35500/77277] Elapsed 115m 46s (remain 136m 14s) Loss: 0.1648(0.2658) Grad: 2.5629  LR: 0.00000991  \n","Epoch: [1][36000/77277] Elapsed 117m 23s (remain 134m 36s) Loss: 0.2399(0.2651) Grad: 5.7289  LR: 0.00000991  \n","Epoch: [1][36500/77277] Elapsed 119m 1s (remain 132m 58s) Loss: 0.1159(0.2644) Grad: 3.0993  LR: 0.00000990  \n","Epoch: [1][37000/77277] Elapsed 120m 39s (remain 131m 20s) Loss: 0.1996(0.2637) Grad: 1.6839  LR: 0.00000989  \n","Epoch: [1][37500/77277] Elapsed 122m 17s (remain 129m 42s) Loss: 0.1149(0.2631) Grad: 2.4209  LR: 0.00000988  \n","Epoch: [1][38000/77277] Elapsed 123m 55s (remain 128m 4s) Loss: 0.1379(0.2623) Grad: 1.8759  LR: 0.00000988  \n","Epoch: [1][38500/77277] Elapsed 125m 33s (remain 126m 27s) Loss: 0.1873(0.2615) Grad: 2.6248  LR: 0.00000987  \n","Epoch: [1][39000/77277] Elapsed 127m 11s (remain 124m 49s) Loss: 0.1488(0.2608) Grad: 3.4950  LR: 0.00000986  \n","Epoch: [1][39500/77277] Elapsed 128m 48s (remain 123m 11s) Loss: 0.1001(0.2602) Grad: 1.6958  LR: 0.00000985  \n","Epoch: [1][40000/77277] Elapsed 130m 26s (remain 121m 33s) Loss: 0.2086(0.2596) Grad: 3.1743  LR: 0.00000984  \n","Epoch: [1][40500/77277] Elapsed 132m 4s (remain 119m 55s) Loss: 0.1747(0.2591) Grad: 2.8750  LR: 0.00000983  \n","Epoch: [1][41000/77277] Elapsed 133m 42s (remain 118m 17s) Loss: 0.1900(0.2586) Grad: 1.7763  LR: 0.00000982  \n","Epoch: [1][41500/77277] Elapsed 135m 20s (remain 116m 39s) Loss: 0.0853(0.2580) Grad: 1.0377  LR: 0.00000981  \n","Epoch: [1][42000/77277] Elapsed 136m 57s (remain 115m 2s) Loss: 0.4438(0.2575) Grad: 3.0919  LR: 0.00000980  \n","Epoch: [1][42500/77277] Elapsed 138m 35s (remain 113m 24s) Loss: 0.4411(0.2570) Grad: 4.5106  LR: 0.00000979  \n","Epoch: [1][43000/77277] Elapsed 140m 13s (remain 111m 46s) Loss: 0.1997(0.2563) Grad: 2.1726  LR: 0.00000978  \n","Epoch: [1][43500/77277] Elapsed 141m 51s (remain 110m 8s) Loss: 0.0650(0.2557) Grad: 1.1804  LR: 0.00000977  \n","Epoch: [1][44000/77277] Elapsed 143m 29s (remain 108m 30s) Loss: 0.0340(0.2551) Grad: 0.7470  LR: 0.00000976  \n","Epoch: [1][44500/77277] Elapsed 145m 6s (remain 106m 52s) Loss: 0.1144(0.2545) Grad: 1.9464  LR: 0.00000974  \n","Epoch: [1][45000/77277] Elapsed 146m 44s (remain 105m 14s) Loss: 0.1240(0.2540) Grad: 3.1359  LR: 0.00000973  \n","Epoch: [1][45500/77277] Elapsed 148m 22s (remain 103m 36s) Loss: 0.0531(0.2534) Grad: 1.2627  LR: 0.00000972  \n","Epoch: [1][46000/77277] Elapsed 150m 0s (remain 101m 59s) Loss: 0.2212(0.2529) Grad: 2.2816  LR: 0.00000971  \n","Epoch: [1][46500/77277] Elapsed 151m 37s (remain 100m 21s) Loss: 0.3373(0.2523) Grad: 4.1130  LR: 0.00000969  \n","Epoch: [1][47000/77277] Elapsed 153m 15s (remain 98m 43s) Loss: 0.2199(0.2518) Grad: 2.3373  LR: 0.00000968  \n","Epoch: [1][47500/77277] Elapsed 154m 53s (remain 97m 5s) Loss: 0.1837(0.2514) Grad: 2.2805  LR: 0.00000967  \n","Epoch: [1][48000/77277] Elapsed 156m 31s (remain 95m 28s) Loss: 0.2287(0.2508) Grad: 4.1980  LR: 0.00000965  \n","Epoch: [1][48500/77277] Elapsed 158m 9s (remain 93m 50s) Loss: 0.1707(0.2504) Grad: 1.9068  LR: 0.00000964  \n","Epoch: [1][49000/77277] Elapsed 159m 47s (remain 92m 12s) Loss: 0.1695(0.2499) Grad: 1.6126  LR: 0.00000963  \n","Epoch: [1][49500/77277] Elapsed 161m 25s (remain 90m 34s) Loss: 0.2883(0.2494) Grad: 3.1348  LR: 0.00000961  \n","Epoch: [1][50000/77277] Elapsed 163m 3s (remain 88m 56s) Loss: 0.3041(0.2489) Grad: 4.0447  LR: 0.00000960  \n","Epoch: [1][50500/77277] Elapsed 164m 41s (remain 87m 19s) Loss: 0.0530(0.2483) Grad: 1.4349  LR: 0.00000958  \n","Epoch: [1][51000/77277] Elapsed 166m 18s (remain 85m 41s) Loss: 0.1625(0.2479) Grad: 2.7984  LR: 0.00000957  \n","Epoch: [1][51500/77277] Elapsed 167m 56s (remain 84m 3s) Loss: 0.2984(0.2475) Grad: 3.1238  LR: 0.00000955  \n","Epoch: [1][52000/77277] Elapsed 169m 34s (remain 82m 25s) Loss: 0.0736(0.2469) Grad: 2.7194  LR: 0.00000954  \n","Epoch: [1][52500/77277] Elapsed 171m 12s (remain 80m 47s) Loss: 0.2568(0.2465) Grad: 3.5275  LR: 0.00000952  \n","Epoch: [1][53000/77277] Elapsed 172m 50s (remain 79m 9s) Loss: 0.1204(0.2461) Grad: 1.9451  LR: 0.00000950  \n","Epoch: [1][53500/77277] Elapsed 174m 27s (remain 77m 31s) Loss: 0.4862(0.2458) Grad: 4.8469  LR: 0.00000949  \n","Epoch: [1][54000/77277] Elapsed 176m 5s (remain 75m 54s) Loss: 0.2030(0.2453) Grad: 2.7222  LR: 0.00000947  \n","Epoch: [1][54500/77277] Elapsed 177m 43s (remain 74m 16s) Loss: 0.3096(0.2448) Grad: 2.5195  LR: 0.00000945  \n","Epoch: [1][55000/77277] Elapsed 179m 20s (remain 72m 38s) Loss: 0.0906(0.2444) Grad: 1.3897  LR: 0.00000944  \n","Epoch: [1][55500/77277] Elapsed 180m 59s (remain 71m 0s) Loss: 0.1745(0.2440) Grad: 2.7542  LR: 0.00000942  \n","Epoch: [1][56000/77277] Elapsed 182m 37s (remain 69m 22s) Loss: 0.0681(0.2436) Grad: 1.2181  LR: 0.00000940  \n","Epoch: [1][56500/77277] Elapsed 184m 15s (remain 67m 45s) Loss: 0.1744(0.2431) Grad: 2.0955  LR: 0.00000938  \n","Epoch: [1][57000/77277] Elapsed 185m 53s (remain 66m 7s) Loss: 0.6575(0.2426) Grad: 5.0666  LR: 0.00000937  \n","Epoch: [1][57500/77277] Elapsed 187m 31s (remain 64m 29s) Loss: 0.1058(0.2422) Grad: 1.9615  LR: 0.00000935  \n","Epoch: [1][58000/77277] Elapsed 189m 9s (remain 62m 51s) Loss: 0.2922(0.2418) Grad: 3.8374  LR: 0.00000933  \n","Epoch: [1][58500/77277] Elapsed 190m 47s (remain 61m 14s) Loss: 0.3348(0.2414) Grad: 3.6657  LR: 0.00000931  \n","Epoch: [1][59000/77277] Elapsed 192m 25s (remain 59m 36s) Loss: 0.1005(0.2409) Grad: 2.1370  LR: 0.00000929  \n","Epoch: [1][59500/77277] Elapsed 194m 3s (remain 57m 58s) Loss: 0.0715(0.2405) Grad: 1.3868  LR: 0.00000927  \n","Epoch: [1][60000/77277] Elapsed 195m 41s (remain 56m 20s) Loss: 0.0488(0.2401) Grad: 1.2547  LR: 0.00000925  \n","Epoch: [1][60500/77277] Elapsed 197m 19s (remain 54m 42s) Loss: 0.1731(0.2398) Grad: 1.9913  LR: 0.00000923  \n","Epoch: [1][61000/77277] Elapsed 198m 57s (remain 53m 5s) Loss: 0.2164(0.2394) Grad: 3.1951  LR: 0.00000921  \n","Epoch: [1][61500/77277] Elapsed 200m 35s (remain 51m 27s) Loss: 0.2221(0.2390) Grad: 3.4993  LR: 0.00000919  \n","Epoch: [1][62000/77277] Elapsed 202m 13s (remain 49m 49s) Loss: 0.1000(0.2387) Grad: 2.1148  LR: 0.00000917  \n","Epoch: [1][62500/77277] Elapsed 203m 51s (remain 48m 11s) Loss: 0.1990(0.2383) Grad: 2.6917  LR: 0.00000915  \n","Epoch: [1][63000/77277] Elapsed 205m 29s (remain 46m 33s) Loss: 0.2866(0.2379) Grad: 6.0103  LR: 0.00000913  \n","Epoch: [1][63500/77277] Elapsed 207m 8s (remain 44m 56s) Loss: 0.2064(0.2375) Grad: 2.1094  LR: 0.00000911  \n","Epoch: [1][64000/77277] Elapsed 208m 46s (remain 43m 18s) Loss: 0.1318(0.2372) Grad: 2.9018  LR: 0.00000909  \n","Epoch: [1][64500/77277] Elapsed 210m 24s (remain 41m 40s) Loss: 0.3760(0.2368) Grad: 6.0049  LR: 0.00000906  \n","Epoch: [1][65000/77277] Elapsed 212m 2s (remain 40m 2s) Loss: 0.3027(0.2365) Grad: 4.4056  LR: 0.00000904  \n","Epoch: [1][65500/77277] Elapsed 213m 40s (remain 38m 24s) Loss: 0.0770(0.2361) Grad: 1.5906  LR: 0.00000902  \n","Epoch: [1][66000/77277] Elapsed 215m 19s (remain 36m 47s) Loss: 0.0906(0.2357) Grad: 1.9934  LR: 0.00000900  \n","Epoch: [1][66500/77277] Elapsed 216m 57s (remain 35m 9s) Loss: 0.3270(0.2353) Grad: 3.9080  LR: 0.00000897  \n","Epoch: [1][67000/77277] Elapsed 218m 35s (remain 33m 31s) Loss: 0.1624(0.2349) Grad: 2.8588  LR: 0.00000895  \n","Epoch: [1][67500/77277] Elapsed 220m 13s (remain 31m 53s) Loss: 0.1687(0.2346) Grad: 2.0635  LR: 0.00000893  \n","Epoch: [1][68000/77277] Elapsed 221m 51s (remain 30m 15s) Loss: 0.2160(0.2343) Grad: 3.1116  LR: 0.00000890  \n","Epoch: [1][68500/77277] Elapsed 223m 29s (remain 28m 37s) Loss: 0.1429(0.2339) Grad: 1.3851  LR: 0.00000888  \n","Epoch: [1][69000/77277] Elapsed 225m 7s (remain 27m 0s) Loss: 0.3392(0.2336) Grad: 2.8569  LR: 0.00000886  \n","Epoch: [1][69500/77277] Elapsed 226m 45s (remain 25m 22s) Loss: 0.0886(0.2332) Grad: 1.8418  LR: 0.00000883  \n","Epoch: [1][70000/77277] Elapsed 228m 23s (remain 23m 44s) Loss: 0.0460(0.2329) Grad: 0.9647  LR: 0.00000881  \n","Epoch: [1][70500/77277] Elapsed 230m 2s (remain 22m 6s) Loss: 0.2286(0.2325) Grad: 4.2774  LR: 0.00000878  \n","Epoch: [1][71000/77277] Elapsed 231m 40s (remain 20m 28s) Loss: 0.3087(0.2321) Grad: 3.1989  LR: 0.00000876  \n","Epoch: [1][71500/77277] Elapsed 233m 18s (remain 18m 50s) Loss: 0.2570(0.2318) Grad: 3.7607  LR: 0.00000873  \n","Epoch: [1][72000/77277] Elapsed 234m 56s (remain 17m 12s) Loss: 0.1796(0.2314) Grad: 3.2315  LR: 0.00000871  \n","Epoch: [1][72500/77277] Elapsed 236m 34s (remain 15m 35s) Loss: 0.1952(0.2311) Grad: 2.9546  LR: 0.00000868  \n","Epoch: [1][73000/77277] Elapsed 238m 12s (remain 13m 57s) Loss: 0.0847(0.2307) Grad: 2.6930  LR: 0.00000866  \n","Epoch: [1][73500/77277] Elapsed 239m 50s (remain 12m 19s) Loss: 0.4687(0.2304) Grad: 6.1148  LR: 0.00000863  \n","Epoch: [1][74000/77277] Elapsed 241m 28s (remain 10m 41s) Loss: 0.1701(0.2301) Grad: 9.5322  LR: 0.00000861  \n","Epoch: [1][74500/77277] Elapsed 243m 6s (remain 9m 3s) Loss: 0.2318(0.2297) Grad: 2.9696  LR: 0.00000858  \n","Epoch: [1][75000/77277] Elapsed 244m 44s (remain 7m 25s) Loss: 0.3069(0.2294) Grad: 3.6596  LR: 0.00000855  \n","Epoch: [1][75500/77277] Elapsed 246m 23s (remain 5m 47s) Loss: 0.1837(0.2291) Grad: 4.6130  LR: 0.00000853  \n","Epoch: [1][76000/77277] Elapsed 248m 1s (remain 4m 9s) Loss: 0.2096(0.2288) Grad: 4.6104  LR: 0.00000850  \n","Epoch: [1][76500/77277] Elapsed 249m 39s (remain 2m 31s) Loss: 0.0506(0.2284) Grad: 1.0001  LR: 0.00000847  \n","Epoch: [1][77000/77277] Elapsed 251m 17s (remain 0m 54s) Loss: 0.2071(0.2281) Grad: 3.4171  LR: 0.00000845  \n","Epoch: [1][77276/77277] Elapsed 252m 11s (remain 0m 0s) Loss: 0.2122(0.2280) Grad: 5.3551  LR: 0.00000843  \n","EVAL: [0/19225] Elapsed 0m 1s (remain 513m 17s) Loss: 0.4853(0.4853) \n","EVAL: [500/19225] Elapsed 1m 23s (remain 51m 53s) Loss: 0.1734(0.2764) \n","EVAL: [1000/19225] Elapsed 2m 47s (remain 50m 42s) Loss: 0.0545(0.2312) \n","EVAL: [1500/19225] Elapsed 4m 7s (remain 48m 38s) Loss: 0.1251(0.2158) \n","EVAL: [2000/19225] Elapsed 5m 30s (remain 47m 25s) Loss: 0.3447(0.2090) \n","EVAL: [2500/19225] Elapsed 6m 55s (remain 46m 20s) Loss: 0.1663(0.1977) \n","EVAL: [3000/19225] Elapsed 8m 23s (remain 45m 23s) Loss: 0.3449(0.1882) \n","EVAL: [3500/19225] Elapsed 9m 54s (remain 44m 28s) Loss: 0.4304(0.1851) \n","EVAL: [4000/19225] Elapsed 11m 24s (remain 43m 25s) Loss: 0.3164(0.1796) \n","EVAL: [4500/19225] Elapsed 12m 48s (remain 41m 52s) Loss: 0.3293(0.1758) \n","EVAL: [5000/19225] Elapsed 14m 14s (remain 40m 29s) Loss: 0.2524(0.1732) \n","EVAL: [5500/19225] Elapsed 15m 42s (remain 39m 12s) Loss: 0.3948(0.1721) \n","EVAL: [6000/19225] Elapsed 17m 10s (remain 37m 51s) Loss: 0.0146(0.1712) \n","EVAL: [6500/19225] Elapsed 18m 46s (remain 36m 44s) Loss: 0.1990(0.1684) \n","EVAL: [7000/19225] Elapsed 20m 20s (remain 35m 31s) Loss: 0.1508(0.1661) \n","EVAL: [7500/19225] Elapsed 21m 53s (remain 34m 13s) Loss: 0.2071(0.1639) \n","EVAL: [8000/19225] Elapsed 23m 24s (remain 32m 50s) Loss: 0.1672(0.1627) \n","EVAL: [8500/19225] Elapsed 24m 54s (remain 31m 25s) Loss: 0.1798(0.1621) \n","EVAL: [9000/19225] Elapsed 26m 20s (remain 29m 55s) Loss: 0.0404(0.1611) \n","EVAL: [9500/19225] Elapsed 27m 56s (remain 28m 35s) Loss: 0.0041(0.1611) \n","EVAL: [10000/19225] Elapsed 29m 27s (remain 27m 10s) Loss: 0.0723(0.1612) \n","EVAL: [10500/19225] Elapsed 31m 1s (remain 25m 46s) Loss: 0.3519(0.1611) \n","EVAL: [11000/19225] Elapsed 32m 37s (remain 24m 23s) Loss: 0.0097(0.1610) \n","EVAL: [11500/19225] Elapsed 34m 12s (remain 22m 58s) Loss: 0.3754(0.1606) \n","EVAL: [12000/19225] Elapsed 35m 50s (remain 21m 34s) Loss: 0.1806(0.1605) \n","EVAL: [12500/19225] Elapsed 37m 28s (remain 20m 9s) Loss: 0.1683(0.1607) \n","EVAL: [13000/19225] Elapsed 39m 7s (remain 18m 43s) Loss: 0.0221(0.1602) \n","EVAL: [13500/19225] Elapsed 40m 46s (remain 17m 17s) Loss: 0.1526(0.1603) \n","EVAL: [14000/19225] Elapsed 42m 22s (remain 15m 48s) Loss: 0.0060(0.1611) \n","EVAL: [14500/19225] Elapsed 44m 3s (remain 14m 21s) Loss: 0.2063(0.1614) \n","EVAL: [15000/19225] Elapsed 45m 45s (remain 12m 53s) Loss: 0.7448(0.1620) \n","EVAL: [15500/19225] Elapsed 47m 24s (remain 11m 23s) Loss: 0.2880(0.1625) \n","EVAL: [16000/19225] Elapsed 49m 5s (remain 9m 53s) Loss: 0.0415(0.1626) \n","EVAL: [16500/19225] Elapsed 50m 46s (remain 8m 22s) Loss: 0.0894(0.1633) \n","EVAL: [17000/19225] Elapsed 52m 27s (remain 6m 51s) Loss: 0.4763(0.1642) \n","EVAL: [17500/19225] Elapsed 54m 8s (remain 5m 19s) Loss: 0.1826(0.1652) \n","EVAL: [18000/19225] Elapsed 55m 51s (remain 3m 47s) Loss: 0.0637(0.1661) \n","EVAL: [18500/19225] Elapsed 57m 35s (remain 2m 15s) Loss: 0.2147(0.1678) \n","EVAL: [19000/19225] Elapsed 59m 24s (remain 0m 42s) Loss: 0.1883(0.1699) \n","EVAL: [19224/19225] Elapsed 60m 18s (remain 0m 0s) Loss: 0.1854(0.1717) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - Save Best Score: 0.5361 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5361 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.2280  avg_val_loss: 0.1717  time: 18862s\n","Epoch 1 - Score: 0.5361 - Threshold: 0.09300\n","Epoch: [2][0/77277] Elapsed 0m 1s (remain 2320m 9s) Loss: 0.2475(0.2475) Grad: 2.4690  LR: 0.00000843  \n","Epoch: [2][500/77277] Elapsed 1m 39s (remain 254m 34s) Loss: 0.1704(0.1749) Grad: 2.6570  LR: 0.00000840  \n","Epoch: [2][1000/77277] Elapsed 3m 17s (remain 250m 48s) Loss: 0.1883(0.1668) Grad: 5.2302  LR: 0.00000838  \n","Epoch: [2][1500/77277] Elapsed 4m 55s (remain 248m 22s) Loss: 0.2186(0.1713) Grad: 3.5586  LR: 0.00000835  \n","Epoch: [2][2000/77277] Elapsed 6m 33s (remain 246m 28s) Loss: 0.1087(0.1695) Grad: 5.0236  LR: 0.00000832  \n","Epoch: [2][2500/77277] Elapsed 8m 10s (remain 244m 34s) Loss: 0.1341(0.1696) Grad: 2.2775  LR: 0.00000829  \n","Epoch: [2][3000/77277] Elapsed 9m 48s (remain 242m 46s) Loss: 0.3447(0.1694) Grad: 4.9029  LR: 0.00000826  \n","Epoch: [2][3500/77277] Elapsed 11m 26s (remain 241m 5s) Loss: 0.1131(0.1692) Grad: 3.2673  LR: 0.00000823  \n","Epoch: [2][4000/77277] Elapsed 13m 4s (remain 239m 23s) Loss: 0.3313(0.1681) Grad: 4.4280  LR: 0.00000821  \n","Epoch: [2][4500/77277] Elapsed 14m 42s (remain 237m 43s) Loss: 0.0187(0.1675) Grad: 0.4312  LR: 0.00000818  \n","Epoch: [2][5000/77277] Elapsed 16m 19s (remain 236m 0s) Loss: 0.1762(0.1672) Grad: 4.4975  LR: 0.00000815  \n","Epoch: [2][5500/77277] Elapsed 17m 57s (remain 234m 19s) Loss: 0.2276(0.1668) Grad: 2.7139  LR: 0.00000812  \n","Epoch: [2][6000/77277] Elapsed 19m 35s (remain 232m 38s) Loss: 0.1865(0.1670) Grad: 4.9578  LR: 0.00000809  \n","Epoch: [2][6500/77277] Elapsed 21m 13s (remain 230m 59s) Loss: 0.0961(0.1670) Grad: 2.1755  LR: 0.00000806  \n","Epoch: [2][7000/77277] Elapsed 22m 50s (remain 229m 19s) Loss: 0.1145(0.1669) Grad: 5.8354  LR: 0.00000803  \n","Epoch: [2][7500/77277] Elapsed 24m 28s (remain 227m 41s) Loss: 0.3297(0.1669) Grad: 5.2022  LR: 0.00000800  \n","Epoch: [2][8000/77277] Elapsed 26m 6s (remain 226m 2s) Loss: 0.0656(0.1667) Grad: 2.1235  LR: 0.00000797  \n","Epoch: [2][8500/77277] Elapsed 27m 44s (remain 224m 23s) Loss: 0.1009(0.1666) Grad: 4.3071  LR: 0.00000794  \n","Epoch: [2][9000/77277] Elapsed 29m 22s (remain 222m 45s) Loss: 0.0556(0.1666) Grad: 1.6838  LR: 0.00000791  \n","Epoch: [2][9500/77277] Elapsed 31m 0s (remain 221m 9s) Loss: 0.1867(0.1667) Grad: 4.9915  LR: 0.00000788  \n","Epoch: [2][10000/77277] Elapsed 32m 37s (remain 219m 30s) Loss: 0.1277(0.1663) Grad: 5.3392  LR: 0.00000785  \n","Epoch: [2][10500/77277] Elapsed 34m 15s (remain 217m 51s) Loss: 0.1197(0.1663) Grad: 6.8303  LR: 0.00000782  \n","Epoch: [2][11000/77277] Elapsed 35m 53s (remain 216m 13s) Loss: 0.0189(0.1660) Grad: 0.5947  LR: 0.00000778  \n","Epoch: [2][11500/77277] Elapsed 37m 31s (remain 214m 36s) Loss: 0.1902(0.1658) Grad: 4.8798  LR: 0.00000775  \n","Epoch: [2][12000/77277] Elapsed 39m 9s (remain 212m 57s) Loss: 0.2607(0.1655) Grad: 6.7763  LR: 0.00000772  \n","Epoch: [2][12500/77277] Elapsed 40m 47s (remain 211m 20s) Loss: 0.0948(0.1653) Grad: 4.5657  LR: 0.00000769  \n","Epoch: [2][13000/77277] Elapsed 42m 24s (remain 209m 41s) Loss: 0.1016(0.1653) Grad: 2.3388  LR: 0.00000766  \n","Epoch: [2][13500/77277] Elapsed 44m 2s (remain 208m 3s) Loss: 0.0952(0.1653) Grad: 2.6530  LR: 0.00000763  \n","Epoch: [2][14000/77277] Elapsed 45m 40s (remain 206m 24s) Loss: 0.1335(0.1651) Grad: 4.3008  LR: 0.00000759  \n","Epoch: [2][14500/77277] Elapsed 47m 18s (remain 204m 46s) Loss: 0.1201(0.1650) Grad: 2.8428  LR: 0.00000756  \n","Epoch: [2][15000/77277] Elapsed 48m 56s (remain 203m 9s) Loss: 0.1100(0.1648) Grad: 2.8978  LR: 0.00000753  \n","Epoch: [2][15500/77277] Elapsed 50m 33s (remain 201m 31s) Loss: 0.1989(0.1646) Grad: 4.9753  LR: 0.00000750  \n","Epoch: [2][16000/77277] Elapsed 52m 11s (remain 199m 53s) Loss: 0.2015(0.1645) Grad: 3.8899  LR: 0.00000746  \n","Epoch: [2][16500/77277] Elapsed 53m 49s (remain 198m 16s) Loss: 0.1163(0.1646) Grad: 4.9166  LR: 0.00000743  \n","Epoch: [2][17000/77277] Elapsed 55m 27s (remain 196m 38s) Loss: 0.2421(0.1644) Grad: 8.6170  LR: 0.00000740  \n","Epoch: [2][17500/77277] Elapsed 57m 5s (remain 195m 0s) Loss: 0.1034(0.1644) Grad: 1.8187  LR: 0.00000737  \n","Epoch: [2][18000/77277] Elapsed 58m 43s (remain 193m 22s) Loss: 0.1758(0.1642) Grad: 4.0403  LR: 0.00000733  \n","Epoch: [2][18500/77277] Elapsed 60m 21s (remain 191m 45s) Loss: 0.3648(0.1642) Grad: 4.5955  LR: 0.00000730  \n","Epoch: [2][19000/77277] Elapsed 61m 59s (remain 190m 7s) Loss: 0.1165(0.1643) Grad: 2.3345  LR: 0.00000727  \n","Epoch: [2][19500/77277] Elapsed 63m 37s (remain 188m 29s) Loss: 0.0343(0.1642) Grad: 0.8309  LR: 0.00000723  \n","Epoch: [2][20000/77277] Elapsed 65m 15s (remain 186m 51s) Loss: 0.1373(0.1641) Grad: 6.9697  LR: 0.00000720  \n","Epoch: [2][20500/77277] Elapsed 66m 52s (remain 185m 13s) Loss: 0.0758(0.1642) Grad: 1.6426  LR: 0.00000716  \n","Epoch: [2][21000/77277] Elapsed 68m 30s (remain 183m 35s) Loss: 0.3576(0.1640) Grad: 5.2518  LR: 0.00000713  \n","Epoch: [2][21500/77277] Elapsed 70m 8s (remain 181m 57s) Loss: 0.0305(0.1638) Grad: 1.6855  LR: 0.00000710  \n","Epoch: [2][22000/77277] Elapsed 71m 46s (remain 180m 19s) Loss: 0.2485(0.1637) Grad: 4.1742  LR: 0.00000706  \n","Epoch: [2][22500/77277] Elapsed 73m 24s (remain 178m 41s) Loss: 0.0984(0.1636) Grad: 3.2091  LR: 0.00000703  \n","Epoch: [2][23000/77277] Elapsed 75m 2s (remain 177m 4s) Loss: 0.1652(0.1635) Grad: 3.8800  LR: 0.00000699  \n","Epoch: [2][23500/77277] Elapsed 76m 40s (remain 175m 26s) Loss: 0.2586(0.1633) Grad: 6.0545  LR: 0.00000696  \n","Epoch: [2][24000/77277] Elapsed 78m 18s (remain 173m 48s) Loss: 0.3005(0.1632) Grad: 4.5901  LR: 0.00000692  \n","Epoch: [2][24500/77277] Elapsed 79m 56s (remain 172m 11s) Loss: 0.2344(0.1631) Grad: 4.9207  LR: 0.00000689  \n","Epoch: [2][25000/77277] Elapsed 81m 34s (remain 170m 33s) Loss: 0.1540(0.1631) Grad: 2.9719  LR: 0.00000685  \n","Epoch: [2][25500/77277] Elapsed 83m 12s (remain 168m 55s) Loss: 0.1928(0.1631) Grad: 4.2176  LR: 0.00000682  \n","Epoch: [2][26000/77277] Elapsed 84m 50s (remain 167m 18s) Loss: 0.1243(0.1630) Grad: 4.0503  LR: 0.00000678  \n","Epoch: [2][26500/77277] Elapsed 86m 28s (remain 165m 40s) Loss: 0.0930(0.1630) Grad: 5.3753  LR: 0.00000675  \n","Epoch: [2][27000/77277] Elapsed 88m 6s (remain 164m 2s) Loss: 0.2457(0.1629) Grad: 7.6545  LR: 0.00000671  \n","Epoch: [2][27500/77277] Elapsed 89m 43s (remain 162m 24s) Loss: 0.1250(0.1628) Grad: 3.2967  LR: 0.00000668  \n","Epoch: [2][28000/77277] Elapsed 91m 21s (remain 160m 46s) Loss: 0.2118(0.1627) Grad: 5.1593  LR: 0.00000664  \n","Epoch: [2][28500/77277] Elapsed 92m 59s (remain 159m 8s) Loss: 0.0975(0.1625) Grad: 1.1789  LR: 0.00000661  \n","Epoch: [2][29000/77277] Elapsed 94m 37s (remain 157m 31s) Loss: 0.1311(0.1625) Grad: 2.5614  LR: 0.00000657  \n","Epoch: [2][29500/77277] Elapsed 96m 15s (remain 155m 53s) Loss: 0.2138(0.1624) Grad: 6.4730  LR: 0.00000654  \n","Epoch: [2][30000/77277] Elapsed 97m 53s (remain 154m 15s) Loss: 0.0463(0.1623) Grad: 2.3716  LR: 0.00000650  \n","Epoch: [2][30500/77277] Elapsed 99m 31s (remain 152m 37s) Loss: 0.0985(0.1622) Grad: 2.7961  LR: 0.00000646  \n","Epoch: [2][31000/77277] Elapsed 101m 9s (remain 150m 59s) Loss: 0.2245(0.1621) Grad: 2.6013  LR: 0.00000643  \n","Epoch: [2][31500/77277] Elapsed 102m 47s (remain 149m 22s) Loss: 0.1041(0.1620) Grad: 3.0732  LR: 0.00000639  \n","Epoch: [2][32000/77277] Elapsed 104m 25s (remain 147m 44s) Loss: 0.0462(0.1619) Grad: 2.6953  LR: 0.00000636  \n","Epoch: [2][32500/77277] Elapsed 106m 3s (remain 146m 6s) Loss: 0.0252(0.1617) Grad: 0.9640  LR: 0.00000632  \n","Epoch: [2][33000/77277] Elapsed 107m 41s (remain 144m 28s) Loss: 0.3878(0.1617) Grad: 3.6956  LR: 0.00000628  \n","Epoch: [2][33500/77277] Elapsed 109m 19s (remain 142m 50s) Loss: 0.3375(0.1616) Grad: 4.9010  LR: 0.00000625  \n","Epoch: [2][34000/77277] Elapsed 110m 57s (remain 141m 13s) Loss: 0.2123(0.1616) Grad: 5.8147  LR: 0.00000621  \n","Epoch: [2][34500/77277] Elapsed 112m 35s (remain 139m 35s) Loss: 0.0478(0.1615) Grad: 2.8118  LR: 0.00000617  \n","Epoch: [2][35000/77277] Elapsed 114m 12s (remain 137m 57s) Loss: 0.2093(0.1614) Grad: 8.1125  LR: 0.00000614  \n","Epoch: [2][35500/77277] Elapsed 115m 50s (remain 136m 19s) Loss: 0.0186(0.1612) Grad: 0.5842  LR: 0.00000610  \n","Epoch: [2][36000/77277] Elapsed 117m 29s (remain 134m 41s) Loss: 0.0766(0.1611) Grad: 3.2909  LR: 0.00000606  \n","Epoch: [2][36500/77277] Elapsed 119m 6s (remain 133m 3s) Loss: 0.3664(0.1611) Grad: 7.4113  LR: 0.00000603  \n","Epoch: [2][37000/77277] Elapsed 120m 44s (remain 131m 26s) Loss: 0.1629(0.1611) Grad: 5.7462  LR: 0.00000599  \n","Epoch: [2][37500/77277] Elapsed 122m 22s (remain 129m 48s) Loss: 0.1676(0.1610) Grad: 4.9475  LR: 0.00000595  \n","Epoch: [2][38000/77277] Elapsed 124m 0s (remain 128m 10s) Loss: 0.0226(0.1609) Grad: 1.2318  LR: 0.00000592  \n","Epoch: [2][38500/77277] Elapsed 125m 38s (remain 126m 32s) Loss: 0.1436(0.1608) Grad: 6.6433  LR: 0.00000588  \n","Epoch: [2][39000/77277] Elapsed 127m 16s (remain 124m 54s) Loss: 0.1887(0.1607) Grad: 9.9852  LR: 0.00000584  \n","Epoch: [2][39500/77277] Elapsed 128m 54s (remain 123m 17s) Loss: 0.2356(0.1607) Grad: 6.6869  LR: 0.00000580  \n","Epoch: [2][40000/77277] Elapsed 130m 32s (remain 121m 39s) Loss: 0.1699(0.1606) Grad: 3.2082  LR: 0.00000577  \n","Epoch: [2][40500/77277] Elapsed 132m 11s (remain 120m 1s) Loss: 0.1928(0.1605) Grad: 4.4318  LR: 0.00000573  \n","Epoch: [2][41000/77277] Elapsed 133m 49s (remain 118m 23s) Loss: 0.1274(0.1604) Grad: 3.0524  LR: 0.00000569  \n","Epoch: [2][41500/77277] Elapsed 135m 27s (remain 116m 45s) Loss: 0.0800(0.1603) Grad: 2.6862  LR: 0.00000566  \n","Epoch: [2][42000/77277] Elapsed 137m 5s (remain 115m 8s) Loss: 0.1679(0.1603) Grad: 5.4083  LR: 0.00000562  \n","Epoch: [2][42500/77277] Elapsed 138m 43s (remain 113m 30s) Loss: 0.0840(0.1602) Grad: 3.4583  LR: 0.00000558  \n","Epoch: [2][43000/77277] Elapsed 140m 21s (remain 111m 52s) Loss: 0.1130(0.1601) Grad: 5.1611  LR: 0.00000554  \n","Epoch: [2][43500/77277] Elapsed 141m 59s (remain 110m 14s) Loss: 0.2980(0.1600) Grad: 6.3887  LR: 0.00000551  \n","Epoch: [2][44000/77277] Elapsed 143m 37s (remain 108m 36s) Loss: 0.2275(0.1599) Grad: 4.0731  LR: 0.00000547  \n","Epoch: [2][44500/77277] Elapsed 145m 15s (remain 106m 58s) Loss: 0.2466(0.1599) Grad: 2.5556  LR: 0.00000543  \n","Epoch: [2][45000/77277] Elapsed 146m 53s (remain 105m 21s) Loss: 0.0575(0.1598) Grad: 2.0515  LR: 0.00000539  \n","Epoch: [2][45500/77277] Elapsed 148m 31s (remain 103m 43s) Loss: 0.1304(0.1597) Grad: 5.8279  LR: 0.00000536  \n","Epoch: [2][46000/77277] Elapsed 150m 9s (remain 102m 5s) Loss: 0.1656(0.1597) Grad: 4.0959  LR: 0.00000532  \n","Epoch: [2][46500/77277] Elapsed 151m 47s (remain 100m 27s) Loss: 0.2043(0.1596) Grad: 4.4387  LR: 0.00000528  \n","Epoch: [2][47000/77277] Elapsed 153m 25s (remain 98m 49s) Loss: 0.3335(0.1596) Grad: 5.5961  LR: 0.00000524  \n","Epoch: [2][47500/77277] Elapsed 155m 3s (remain 97m 11s) Loss: 0.1350(0.1596) Grad: 2.6803  LR: 0.00000521  \n","Epoch: [2][48000/77277] Elapsed 156m 41s (remain 95m 33s) Loss: 0.1113(0.1595) Grad: 3.9862  LR: 0.00000517  \n","Epoch: [2][48500/77277] Elapsed 158m 19s (remain 93m 56s) Loss: 0.2513(0.1594) Grad: 5.7538  LR: 0.00000513  \n","Epoch: [2][49000/77277] Elapsed 159m 57s (remain 92m 18s) Loss: 0.2234(0.1593) Grad: 7.7607  LR: 0.00000509  \n","Epoch: [2][49500/77277] Elapsed 161m 35s (remain 90m 40s) Loss: 0.0350(0.1593) Grad: 1.6929  LR: 0.00000505  \n","Epoch: [2][50000/77277] Elapsed 163m 13s (remain 89m 2s) Loss: 0.1153(0.1592) Grad: 3.7706  LR: 0.00000502  \n","Epoch: [2][50500/77277] Elapsed 164m 51s (remain 87m 24s) Loss: 0.1597(0.1591) Grad: 7.3618  LR: 0.00000498  \n","Epoch: [2][51000/77277] Elapsed 166m 28s (remain 85m 46s) Loss: 0.2002(0.1590) Grad: 4.8646  LR: 0.00000494  \n","Epoch: [2][51500/77277] Elapsed 168m 6s (remain 84m 8s) Loss: 0.0724(0.1590) Grad: 2.5399  LR: 0.00000490  \n","Epoch: [2][52000/77277] Elapsed 169m 44s (remain 82m 30s) Loss: 0.1142(0.1589) Grad: 4.1055  LR: 0.00000487  \n","Epoch: [2][52500/77277] Elapsed 171m 22s (remain 80m 52s) Loss: 0.0577(0.1589) Grad: 2.0691  LR: 0.00000483  \n","Epoch: [2][53000/77277] Elapsed 173m 0s (remain 79m 14s) Loss: 0.0359(0.1587) Grad: 1.5208  LR: 0.00000479  \n","Epoch: [2][53500/77277] Elapsed 174m 38s (remain 77m 36s) Loss: 0.0513(0.1587) Grad: 2.0011  LR: 0.00000475  \n","Epoch: [2][54000/77277] Elapsed 176m 16s (remain 75m 58s) Loss: 0.0223(0.1586) Grad: 1.1083  LR: 0.00000472  \n","Epoch: [2][54500/77277] Elapsed 177m 54s (remain 74m 20s) Loss: 0.1218(0.1585) Grad: 5.0535  LR: 0.00000468  \n","Epoch: [2][55000/77277] Elapsed 179m 32s (remain 72m 42s) Loss: 0.0457(0.1584) Grad: 2.1486  LR: 0.00000464  \n","Epoch: [2][55500/77277] Elapsed 181m 10s (remain 71m 5s) Loss: 0.1792(0.1583) Grad: 10.1135  LR: 0.00000460  \n","Epoch: [2][56000/77277] Elapsed 182m 48s (remain 69m 27s) Loss: 0.2170(0.1582) Grad: 4.1103  LR: 0.00000457  \n","Epoch: [2][56500/77277] Elapsed 184m 26s (remain 67m 49s) Loss: 0.0599(0.1581) Grad: 4.1082  LR: 0.00000453  \n","Epoch: [2][57000/77277] Elapsed 186m 4s (remain 66m 11s) Loss: 0.0270(0.1581) Grad: 0.9952  LR: 0.00000449  \n","Epoch: [2][57500/77277] Elapsed 187m 42s (remain 64m 33s) Loss: 0.0996(0.1580) Grad: 1.9899  LR: 0.00000445  \n","Epoch: [2][58000/77277] Elapsed 189m 20s (remain 62m 55s) Loss: 0.1014(0.1579) Grad: 2.6959  LR: 0.00000442  \n","Epoch: [2][58500/77277] Elapsed 190m 58s (remain 61m 17s) Loss: 0.4544(0.1578) Grad: 8.6931  LR: 0.00000438  \n","Epoch: [2][59000/77277] Elapsed 192m 36s (remain 59m 39s) Loss: 0.1096(0.1577) Grad: 4.3774  LR: 0.00000434  \n","Epoch: [2][59500/77277] Elapsed 194m 14s (remain 58m 1s) Loss: 0.0966(0.1576) Grad: 3.6148  LR: 0.00000430  \n","Epoch: [2][60000/77277] Elapsed 195m 52s (remain 56m 23s) Loss: 0.0706(0.1575) Grad: 1.5523  LR: 0.00000427  \n","Epoch: [2][60500/77277] Elapsed 197m 30s (remain 54m 45s) Loss: 0.2282(0.1575) Grad: 5.7158  LR: 0.00000423  \n","Epoch: [2][61000/77277] Elapsed 199m 8s (remain 53m 7s) Loss: 0.0904(0.1574) Grad: 3.1534  LR: 0.00000419  \n","Epoch: [2][61500/77277] Elapsed 200m 46s (remain 51m 30s) Loss: 0.2099(0.1574) Grad: 4.9355  LR: 0.00000416  \n","Epoch: [2][62000/77277] Elapsed 202m 23s (remain 49m 52s) Loss: 0.2234(0.1573) Grad: 3.6957  LR: 0.00000412  \n","Epoch: [2][62500/77277] Elapsed 204m 1s (remain 48m 14s) Loss: 0.1070(0.1572) Grad: 2.1737  LR: 0.00000408  \n","Epoch: [2][63000/77277] Elapsed 205m 39s (remain 46m 36s) Loss: 0.0601(0.1571) Grad: 5.6015  LR: 0.00000404  \n","Epoch: [2][63500/77277] Elapsed 207m 17s (remain 44m 58s) Loss: 0.0734(0.1570) Grad: 2.8030  LR: 0.00000401  \n","Epoch: [2][64000/77277] Elapsed 208m 55s (remain 43m 20s) Loss: 0.1296(0.1568) Grad: 3.1559  LR: 0.00000397  \n","Epoch: [2][64500/77277] Elapsed 210m 33s (remain 41m 42s) Loss: 0.3958(0.1568) Grad: 7.4116  LR: 0.00000393  \n","Epoch: [2][65000/77277] Elapsed 212m 11s (remain 40m 4s) Loss: 0.0379(0.1567) Grad: 1.4947  LR: 0.00000390  \n","Epoch: [2][65500/77277] Elapsed 213m 49s (remain 38m 26s) Loss: 0.0914(0.1566) Grad: 2.4172  LR: 0.00000386  \n","Epoch: [2][66000/77277] Elapsed 215m 27s (remain 36m 48s) Loss: 0.1399(0.1566) Grad: 4.0332  LR: 0.00000382  \n","Epoch: [2][66500/77277] Elapsed 217m 5s (remain 35m 10s) Loss: 0.0936(0.1564) Grad: 2.8173  LR: 0.00000379  \n","Epoch: [2][67000/77277] Elapsed 218m 43s (remain 33m 32s) Loss: 0.0634(0.1563) Grad: 3.1577  LR: 0.00000375  \n","Epoch: [2][67500/77277] Elapsed 220m 21s (remain 31m 54s) Loss: 0.1027(0.1563) Grad: 4.7866  LR: 0.00000371  \n","Epoch: [2][68000/77277] Elapsed 221m 59s (remain 30m 16s) Loss: 0.0849(0.1563) Grad: 1.4149  LR: 0.00000368  \n","Epoch: [2][68500/77277] Elapsed 223m 37s (remain 28m 38s) Loss: 0.2165(0.1562) Grad: 3.1907  LR: 0.00000364  \n","Epoch: [2][69000/77277] Elapsed 225m 15s (remain 27m 1s) Loss: 0.2547(0.1562) Grad: 7.8556  LR: 0.00000361  \n","Epoch: [2][69500/77277] Elapsed 226m 53s (remain 25m 23s) Loss: 0.1700(0.1560) Grad: 3.9931  LR: 0.00000357  \n","Epoch: [2][70000/77277] Elapsed 228m 31s (remain 23m 45s) Loss: 0.0401(0.1560) Grad: 1.4975  LR: 0.00000353  \n","Epoch: [2][70500/77277] Elapsed 230m 9s (remain 22m 7s) Loss: 0.0755(0.1559) Grad: 5.8283  LR: 0.00000350  \n","Epoch: [2][71000/77277] Elapsed 231m 47s (remain 20m 29s) Loss: 0.1845(0.1558) Grad: 5.1680  LR: 0.00000346  \n","Epoch: [2][71500/77277] Elapsed 233m 25s (remain 18m 51s) Loss: 0.2745(0.1557) Grad: 6.5840  LR: 0.00000343  \n","Epoch: [2][72000/77277] Elapsed 235m 3s (remain 17m 13s) Loss: 0.1320(0.1556) Grad: 4.6246  LR: 0.00000339  \n","Epoch: [2][72500/77277] Elapsed 236m 41s (remain 15m 35s) Loss: 0.1561(0.1555) Grad: 4.4801  LR: 0.00000335  \n","Epoch: [2][73000/77277] Elapsed 238m 19s (remain 13m 57s) Loss: 0.2239(0.1554) Grad: 3.8279  LR: 0.00000332  \n","Epoch: [2][73500/77277] Elapsed 239m 57s (remain 12m 19s) Loss: 0.3782(0.1553) Grad: 5.4596  LR: 0.00000328  \n","Epoch: [2][74000/77277] Elapsed 241m 35s (remain 10m 41s) Loss: 0.2008(0.1553) Grad: 3.3296  LR: 0.00000325  \n","Epoch: [2][74500/77277] Elapsed 243m 13s (remain 9m 3s) Loss: 0.1344(0.1553) Grad: 2.8623  LR: 0.00000321  \n","Epoch: [2][75000/77277] Elapsed 244m 51s (remain 7m 25s) Loss: 0.0485(0.1552) Grad: 1.7080  LR: 0.00000318  \n","Epoch: [2][75500/77277] Elapsed 246m 29s (remain 5m 47s) Loss: 0.1746(0.1551) Grad: 6.0201  LR: 0.00000314  \n","Epoch: [2][76000/77277] Elapsed 248m 7s (remain 4m 9s) Loss: 0.2160(0.1550) Grad: 3.6775  LR: 0.00000311  \n","Epoch: [2][76500/77277] Elapsed 249m 45s (remain 2m 32s) Loss: 0.2854(0.1550) Grad: 4.5333  LR: 0.00000307  \n","Epoch: [2][77000/77277] Elapsed 251m 23s (remain 0m 54s) Loss: 0.0428(0.1549) Grad: 2.6484  LR: 0.00000304  \n","Epoch: [2][77276/77277] Elapsed 252m 18s (remain 0m 0s) Loss: 0.0321(0.1549) Grad: 1.4191  LR: 0.00000302  \n","EVAL: [0/19225] Elapsed 0m 1s (remain 488m 48s) Loss: 0.2525(0.2525) \n","EVAL: [500/19225] Elapsed 1m 22s (remain 51m 36s) Loss: 0.2187(0.2754) \n","EVAL: [1000/19225] Elapsed 2m 46s (remain 50m 31s) Loss: 0.0316(0.2247) \n","EVAL: [1500/19225] Elapsed 4m 6s (remain 48m 29s) Loss: 0.1593(0.2078) \n","EVAL: [2000/19225] Elapsed 5m 29s (remain 47m 19s) Loss: 0.3759(0.2028) \n","EVAL: [2500/19225] Elapsed 6m 55s (remain 46m 15s) Loss: 0.1650(0.1916) \n","EVAL: [3000/19225] Elapsed 8m 22s (remain 45m 18s) Loss: 0.4084(0.1818) \n","EVAL: [3500/19225] Elapsed 9m 53s (remain 44m 23s) Loss: 0.3913(0.1778) \n","EVAL: [4000/19225] Elapsed 11m 23s (remain 43m 20s) Loss: 0.3906(0.1716) \n","EVAL: [4500/19225] Elapsed 12m 47s (remain 41m 49s) Loss: 0.3093(0.1678) \n","EVAL: [5000/19225] Elapsed 14m 12s (remain 40m 25s) Loss: 0.2208(0.1649) \n","EVAL: [5500/19225] Elapsed 15m 41s (remain 39m 8s) Loss: 0.4356(0.1634) \n","EVAL: [6000/19225] Elapsed 17m 9s (remain 37m 48s) Loss: 0.0038(0.1628) \n","EVAL: [6500/19225] Elapsed 18m 45s (remain 36m 42s) Loss: 0.0851(0.1596) \n","EVAL: [7000/19225] Elapsed 20m 19s (remain 35m 28s) Loss: 0.1214(0.1575) \n","EVAL: [7500/19225] Elapsed 21m 52s (remain 34m 11s) Loss: 0.0999(0.1549) \n","EVAL: [8000/19225] Elapsed 23m 23s (remain 32m 48s) Loss: 0.1704(0.1536) \n","EVAL: [8500/19225] Elapsed 24m 53s (remain 31m 24s) Loss: 0.0942(0.1526) \n","EVAL: [9000/19225] Elapsed 26m 19s (remain 29m 53s) Loss: 0.0121(0.1514) \n","EVAL: [9500/19225] Elapsed 27m 54s (remain 28m 34s) Loss: 0.0008(0.1508) \n","EVAL: [10000/19225] Elapsed 29m 26s (remain 27m 9s) Loss: 0.0085(0.1504) \n","EVAL: [10500/19225] Elapsed 31m 0s (remain 25m 45s) Loss: 0.2834(0.1500) \n","EVAL: [11000/19225] Elapsed 32m 36s (remain 24m 22s) Loss: 0.0033(0.1495) \n","EVAL: [11500/19225] Elapsed 34m 11s (remain 22m 57s) Loss: 0.4548(0.1492) \n","EVAL: [12000/19225] Elapsed 35m 49s (remain 21m 33s) Loss: 0.1198(0.1489) \n","EVAL: [12500/19225] Elapsed 37m 27s (remain 20m 8s) Loss: 0.1136(0.1488) \n","EVAL: [13000/19225] Elapsed 39m 6s (remain 18m 43s) Loss: 0.0020(0.1482) \n","EVAL: [13500/19225] Elapsed 40m 45s (remain 17m 16s) Loss: 0.0268(0.1480) \n","EVAL: [14000/19225] Elapsed 42m 21s (remain 15m 48s) Loss: 0.0017(0.1488) \n","EVAL: [14500/19225] Elapsed 44m 3s (remain 14m 21s) Loss: 0.0349(0.1489) \n","EVAL: [15000/19225] Elapsed 45m 45s (remain 12m 53s) Loss: 0.6252(0.1493) \n","EVAL: [15500/19225] Elapsed 47m 24s (remain 11m 23s) Loss: 0.1656(0.1496) \n","EVAL: [16000/19225] Elapsed 49m 4s (remain 9m 53s) Loss: 0.0177(0.1496) \n","EVAL: [16500/19225] Elapsed 50m 46s (remain 8m 22s) Loss: 0.0366(0.1501) \n","EVAL: [17000/19225] Elapsed 52m 27s (remain 6m 51s) Loss: 0.5560(0.1507) \n","EVAL: [17500/19225] Elapsed 54m 8s (remain 5m 20s) Loss: 0.1093(0.1514) \n","EVAL: [18000/19225] Elapsed 55m 52s (remain 3m 47s) Loss: 0.1377(0.1521) \n","EVAL: [18500/19225] Elapsed 57m 36s (remain 2m 15s) Loss: 0.2278(0.1537) \n","EVAL: [19000/19225] Elapsed 59m 24s (remain 0m 42s) Loss: 0.0910(0.1556) \n","EVAL: [19224/19225] Elapsed 60m 20s (remain 0m 0s) Loss: 0.1745(0.1574) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - Save Best Score: 0.6039 Model\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 11, in <module>\n","    _oof_df = train_loop(train, correlations, fold, CFG)\n","  File \"<ipython-input-17-02c5098fcfa5>\", line 125, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","Message: 'Epoch 2 - Save Best Score: 0.6039 Model'\n","Arguments: ()\n","INFO:__main__:Epoch 2 - Save Best Score: 0.6039 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 - avg_train_loss: 0.1549  avg_val_loss: 0.1574  time: 18863s\n","Epoch 2 - Score: 0.6039 - Threshold: 0.05600\n","Epoch: [3][0/77277] Elapsed 0m 1s (remain 2540m 0s) Loss: 0.0120(0.0120) Grad: 0.5102  LR: 0.00000302  \n","Epoch: [3][500/77277] Elapsed 1m 40s (remain 255m 33s) Loss: 0.0325(0.1266) Grad: 1.8825  LR: 0.00000299  \n","Epoch: [3][1000/77277] Elapsed 3m 17s (remain 251m 16s) Loss: 0.1933(0.1221) Grad: 4.8757  LR: 0.00000295  \n","Epoch: [3][1500/77277] Elapsed 4m 55s (remain 248m 42s) Loss: 0.0290(0.1215) Grad: 2.4949  LR: 0.00000292  \n","Epoch: [3][2000/77277] Elapsed 6m 33s (remain 246m 37s) Loss: 0.0783(0.1227) Grad: 7.3949  LR: 0.00000288  \n","Epoch: [3][2500/77277] Elapsed 8m 11s (remain 244m 42s) Loss: 0.0606(0.1220) Grad: 4.8824  LR: 0.00000285  \n","Epoch: [3][3000/77277] Elapsed 9m 48s (remain 242m 52s) Loss: 0.1692(0.1223) Grad: 2.9837  LR: 0.00000281  \n","Epoch: [3][3500/77277] Elapsed 11m 26s (remain 241m 7s) Loss: 0.1177(0.1220) Grad: 4.9488  LR: 0.00000278  \n","Epoch: [3][4000/77277] Elapsed 13m 4s (remain 239m 22s) Loss: 0.1935(0.1215) Grad: 7.0480  LR: 0.00000275  \n","Epoch: [3][4500/77277] Elapsed 14m 41s (remain 237m 40s) Loss: 0.3704(0.1209) Grad: 7.5323  LR: 0.00000271  \n","Epoch: [3][5000/77277] Elapsed 16m 19s (remain 236m 0s) Loss: 0.0358(0.1207) Grad: 2.1552  LR: 0.00000268  \n","Epoch: [3][5500/77277] Elapsed 17m 57s (remain 234m 19s) Loss: 0.2092(0.1212) Grad: 8.5183  LR: 0.00000265  \n","Epoch: [3][6000/77277] Elapsed 19m 35s (remain 232m 40s) Loss: 0.0490(0.1208) Grad: 1.4451  LR: 0.00000261  \n","Epoch: [3][6500/77277] Elapsed 21m 13s (remain 231m 1s) Loss: 0.0118(0.1213) Grad: 1.8843  LR: 0.00000258  \n","Epoch: [3][7000/77277] Elapsed 22m 51s (remain 229m 22s) Loss: 0.1676(0.1211) Grad: 9.8526  LR: 0.00000255  \n","Epoch: [3][7500/77277] Elapsed 24m 28s (remain 227m 44s) Loss: 0.1984(0.1210) Grad: 4.3968  LR: 0.00000251  \n","Epoch: [3][8000/77277] Elapsed 26m 6s (remain 226m 5s) Loss: 0.2921(0.1212) Grad: 5.5150  LR: 0.00000248  \n","Epoch: [3][8500/77277] Elapsed 27m 44s (remain 224m 25s) Loss: 0.2197(0.1210) Grad: 6.1465  LR: 0.00000245  \n","Epoch: [3][9000/77277] Elapsed 29m 22s (remain 222m 47s) Loss: 0.1860(0.1209) Grad: 3.6202  LR: 0.00000242  \n","Epoch: [3][9500/77277] Elapsed 31m 0s (remain 221m 8s) Loss: 0.0231(0.1210) Grad: 3.8235  LR: 0.00000239  \n","Epoch: [3][10000/77277] Elapsed 32m 37s (remain 219m 29s) Loss: 0.1665(0.1212) Grad: 4.7837  LR: 0.00000235  \n","Epoch: [3][10500/77277] Elapsed 34m 15s (remain 217m 51s) Loss: 0.2477(0.1209) Grad: 5.7471  LR: 0.00000232  \n","Epoch: [3][11000/77277] Elapsed 35m 53s (remain 216m 13s) Loss: 0.0931(0.1210) Grad: 3.0464  LR: 0.00000229  \n","Epoch: [3][11500/77277] Elapsed 37m 31s (remain 214m 36s) Loss: 0.0128(0.1209) Grad: 1.6628  LR: 0.00000226  \n","Epoch: [3][12000/77277] Elapsed 39m 9s (remain 212m 57s) Loss: 0.1432(0.1210) Grad: 5.1362  LR: 0.00000223  \n","Epoch: [3][12500/77277] Elapsed 40m 47s (remain 211m 19s) Loss: 0.1995(0.1209) Grad: 4.2351  LR: 0.00000220  \n","Epoch: [3][13000/77277] Elapsed 42m 24s (remain 209m 41s) Loss: 0.1198(0.1207) Grad: 9.1000  LR: 0.00000216  \n","Epoch: [3][13500/77277] Elapsed 44m 2s (remain 208m 3s) Loss: 0.2269(0.1209) Grad: 4.7543  LR: 0.00000213  \n","Epoch: [3][14000/77277] Elapsed 45m 40s (remain 206m 25s) Loss: 0.1539(0.1206) Grad: 20.7597  LR: 0.00000210  \n","Epoch: [3][14500/77277] Elapsed 47m 18s (remain 204m 48s) Loss: 0.2501(0.1204) Grad: 9.1593  LR: 0.00000207  \n","Epoch: [3][15000/77277] Elapsed 48m 56s (remain 203m 10s) Loss: 0.1397(0.1204) Grad: 8.5881  LR: 0.00000204  \n","Epoch: [3][15500/77277] Elapsed 50m 34s (remain 201m 32s) Loss: 0.1624(0.1203) Grad: 5.8603  LR: 0.00000201  \n","Epoch: [3][16000/77277] Elapsed 52m 12s (remain 199m 54s) Loss: 0.1068(0.1202) Grad: 10.7687  LR: 0.00000198  \n","Epoch: [3][16500/77277] Elapsed 53m 49s (remain 198m 16s) Loss: 0.0606(0.1202) Grad: 4.7031  LR: 0.00000195  \n","Epoch: [3][17000/77277] Elapsed 55m 27s (remain 196m 38s) Loss: 0.2163(0.1203) Grad: 32.6108  LR: 0.00000192  \n","Epoch: [3][17500/77277] Elapsed 57m 5s (remain 194m 59s) Loss: 0.0440(0.1204) Grad: 2.7468  LR: 0.00000189  \n","Epoch: [3][18000/77277] Elapsed 58m 43s (remain 193m 22s) Loss: 0.2847(0.1204) Grad: 31.7874  LR: 0.00000186  \n","Epoch: [3][18500/77277] Elapsed 60m 21s (remain 191m 44s) Loss: 0.0419(0.1205) Grad: 2.9710  LR: 0.00000183  \n","Epoch: [3][19000/77277] Elapsed 61m 59s (remain 190m 6s) Loss: 0.0652(0.1203) Grad: 2.4902  LR: 0.00000180  \n","Epoch: [3][19500/77277] Elapsed 63m 36s (remain 188m 28s) Loss: 0.0709(0.1202) Grad: 7.9398  LR: 0.00000178  \n","Epoch: [3][20000/77277] Elapsed 65m 14s (remain 186m 50s) Loss: 0.0361(0.1202) Grad: 1.9911  LR: 0.00000175  \n","Epoch: [3][20500/77277] Elapsed 66m 52s (remain 185m 12s) Loss: 0.3094(0.1203) Grad: 6.4617  LR: 0.00000172  \n","Epoch: [3][21000/77277] Elapsed 68m 30s (remain 183m 35s) Loss: 0.1365(0.1202) Grad: 5.8813  LR: 0.00000169  \n","Epoch: [3][21500/77277] Elapsed 70m 8s (remain 181m 57s) Loss: 0.4212(0.1202) Grad: 14.0528  LR: 0.00000166  \n","Epoch: [3][22000/77277] Elapsed 71m 46s (remain 180m 19s) Loss: 0.1220(0.1204) Grad: 6.5031  LR: 0.00000163  \n","Epoch: [3][22500/77277] Elapsed 73m 24s (remain 178m 41s) Loss: 0.3694(0.1204) Grad: 6.6212  LR: 0.00000161  \n","Epoch: [3][23000/77277] Elapsed 75m 2s (remain 177m 3s) Loss: 0.1883(0.1205) Grad: 5.9158  LR: 0.00000158  \n","Epoch: [3][23500/77277] Elapsed 76m 39s (remain 175m 25s) Loss: 0.0113(0.1204) Grad: 0.6595  LR: 0.00000155  \n","Epoch: [3][24000/77277] Elapsed 78m 17s (remain 173m 47s) Loss: 0.3999(0.1202) Grad: 19.4222  LR: 0.00000152  \n","Epoch: [3][24500/77277] Elapsed 79m 55s (remain 172m 9s) Loss: 0.0226(0.1202) Grad: 1.4221  LR: 0.00000150  \n","Epoch: [3][25000/77277] Elapsed 81m 33s (remain 170m 32s) Loss: 0.1814(0.1203) Grad: 3.7910  LR: 0.00000147  \n","Epoch: [3][25500/77277] Elapsed 83m 11s (remain 168m 54s) Loss: 0.1334(0.1203) Grad: 8.6463  LR: 0.00000144  \n","Epoch: [3][26000/77277] Elapsed 84m 49s (remain 167m 16s) Loss: 0.1628(0.1202) Grad: 6.8371  LR: 0.00000142  \n","Epoch: [3][26500/77277] Elapsed 86m 27s (remain 165m 38s) Loss: 0.1031(0.1201) Grad: 10.7219  LR: 0.00000139  \n","Epoch: [3][27000/77277] Elapsed 88m 4s (remain 164m 0s) Loss: 0.0630(0.1202) Grad: 3.1705  LR: 0.00000137  \n","Epoch: [3][27500/77277] Elapsed 89m 42s (remain 162m 22s) Loss: 0.0985(0.1201) Grad: 1.6077  LR: 0.00000134  \n","Epoch: [3][28000/77277] Elapsed 91m 20s (remain 160m 45s) Loss: 0.1204(0.1200) Grad: 6.3557  LR: 0.00000131  \n","Epoch: [3][28500/77277] Elapsed 92m 58s (remain 159m 7s) Loss: 0.2219(0.1200) Grad: 16.2555  LR: 0.00000129  \n","Epoch: [3][29000/77277] Elapsed 94m 36s (remain 157m 29s) Loss: 0.0298(0.1200) Grad: 2.7061  LR: 0.00000126  \n","Epoch: [3][29500/77277] Elapsed 96m 14s (remain 155m 51s) Loss: 0.1522(0.1199) Grad: 4.6175  LR: 0.00000124  \n","Epoch: [3][30000/77277] Elapsed 97m 52s (remain 154m 13s) Loss: 0.0468(0.1200) Grad: 5.5472  LR: 0.00000121  \n","Epoch: [3][30500/77277] Elapsed 99m 30s (remain 152m 35s) Loss: 0.1063(0.1200) Grad: 5.0440  LR: 0.00000119  \n","Epoch: [3][31000/77277] Elapsed 101m 7s (remain 150m 57s) Loss: 0.2676(0.1200) Grad: 7.5757  LR: 0.00000117  \n","Epoch: [3][31500/77277] Elapsed 102m 45s (remain 149m 20s) Loss: 0.1276(0.1199) Grad: 4.6264  LR: 0.00000114  \n","Epoch: [3][32000/77277] Elapsed 104m 23s (remain 147m 42s) Loss: 0.0646(0.1198) Grad: 5.4346  LR: 0.00000112  \n","Epoch: [3][32500/77277] Elapsed 106m 1s (remain 146m 4s) Loss: 0.0179(0.1198) Grad: 1.2309  LR: 0.00000109  \n","Epoch: [3][33000/77277] Elapsed 107m 39s (remain 144m 26s) Loss: 0.0338(0.1197) Grad: 3.0086  LR: 0.00000107  \n","Epoch: [3][33500/77277] Elapsed 109m 17s (remain 142m 48s) Loss: 0.1830(0.1197) Grad: 4.8308  LR: 0.00000105  \n","Epoch: [3][34000/77277] Elapsed 110m 55s (remain 141m 11s) Loss: 0.0105(0.1196) Grad: 2.8634  LR: 0.00000102  \n","Epoch: [3][34500/77277] Elapsed 112m 33s (remain 139m 33s) Loss: 0.0416(0.1196) Grad: 3.4020  LR: 0.00000100  \n","Epoch: [3][35000/77277] Elapsed 114m 11s (remain 137m 55s) Loss: 0.1662(0.1196) Grad: 4.9938  LR: 0.00000098  \n","Epoch: [3][35500/77277] Elapsed 115m 49s (remain 136m 17s) Loss: 0.0460(0.1196) Grad: 1.7169  LR: 0.00000096  \n","Epoch: [3][36000/77277] Elapsed 117m 27s (remain 134m 39s) Loss: 0.0909(0.1196) Grad: 14.1724  LR: 0.00000094  \n","Epoch: [3][36500/77277] Elapsed 119m 5s (remain 133m 1s) Loss: 0.0835(0.1195) Grad: 7.7920  LR: 0.00000091  \n","Epoch: [3][37000/77277] Elapsed 120m 42s (remain 131m 24s) Loss: 0.1501(0.1194) Grad: 7.5710  LR: 0.00000089  \n","Epoch: [3][37500/77277] Elapsed 122m 20s (remain 129m 46s) Loss: 0.2042(0.1194) Grad: 8.1629  LR: 0.00000087  \n","Epoch: [3][38000/77277] Elapsed 123m 58s (remain 128m 8s) Loss: 0.0217(0.1194) Grad: 0.9570  LR: 0.00000085  \n","Epoch: [3][38500/77277] Elapsed 125m 36s (remain 126m 30s) Loss: 0.2804(0.1194) Grad: 13.3549  LR: 0.00000083  \n","Epoch: [3][39000/77277] Elapsed 127m 14s (remain 124m 52s) Loss: 0.1304(0.1194) Grad: 11.6949  LR: 0.00000081  \n","Epoch: [3][39500/77277] Elapsed 128m 52s (remain 123m 15s) Loss: 0.0639(0.1193) Grad: 2.8531  LR: 0.00000079  \n","Epoch: [3][40000/77277] Elapsed 130m 30s (remain 121m 37s) Loss: 0.2634(0.1193) Grad: 7.8136  LR: 0.00000077  \n","Epoch: [3][40500/77277] Elapsed 132m 8s (remain 119m 59s) Loss: 0.0679(0.1193) Grad: 4.0899  LR: 0.00000075  \n","Epoch: [3][41000/77277] Elapsed 133m 46s (remain 118m 21s) Loss: 0.1405(0.1193) Grad: 3.8546  LR: 0.00000073  \n","Epoch: [3][41500/77277] Elapsed 135m 24s (remain 116m 43s) Loss: 0.2634(0.1193) Grad: 5.1418  LR: 0.00000071  \n","Epoch: [3][42000/77277] Elapsed 137m 2s (remain 115m 5s) Loss: 0.0209(0.1193) Grad: 3.7272  LR: 0.00000069  \n","Epoch: [3][42500/77277] Elapsed 138m 40s (remain 113m 28s) Loss: 0.1093(0.1192) Grad: 8.7820  LR: 0.00000067  \n","Epoch: [3][43000/77277] Elapsed 140m 18s (remain 111m 50s) Loss: 0.2271(0.1192) Grad: 8.6053  LR: 0.00000065  \n","Epoch: [3][43500/77277] Elapsed 141m 56s (remain 110m 12s) Loss: 0.0117(0.1191) Grad: 0.4781  LR: 0.00000063  \n","Epoch: [3][44000/77277] Elapsed 143m 34s (remain 108m 34s) Loss: 0.1255(0.1191) Grad: 13.4024  LR: 0.00000061  \n","Epoch: [3][44500/77277] Elapsed 145m 11s (remain 106m 56s) Loss: 0.0100(0.1191) Grad: 1.2480  LR: 0.00000060  \n","Epoch: [3][45000/77277] Elapsed 146m 49s (remain 105m 18s) Loss: 0.1323(0.1191) Grad: 5.0455  LR: 0.00000058  \n","Epoch: [3][45500/77277] Elapsed 148m 27s (remain 103m 40s) Loss: 0.0284(0.1191) Grad: 2.1286  LR: 0.00000056  \n","Epoch: [3][46000/77277] Elapsed 150m 5s (remain 102m 3s) Loss: 0.1152(0.1190) Grad: 9.1471  LR: 0.00000054  \n","Epoch: [3][46500/77277] Elapsed 151m 43s (remain 100m 25s) Loss: 0.0860(0.1190) Grad: 10.4641  LR: 0.00000053  \n","Epoch: [3][47000/77277] Elapsed 153m 21s (remain 98m 47s) Loss: 0.2304(0.1190) Grad: 6.7173  LR: 0.00000051  \n","Epoch: [3][47500/77277] Elapsed 154m 59s (remain 97m 9s) Loss: 0.1466(0.1189) Grad: 8.7782  LR: 0.00000049  \n","Epoch: [3][48000/77277] Elapsed 156m 37s (remain 95m 31s) Loss: 0.2660(0.1189) Grad: 8.3850  LR: 0.00000048  \n","Epoch: [3][48500/77277] Elapsed 158m 15s (remain 93m 53s) Loss: 0.0849(0.1188) Grad: 3.5994  LR: 0.00000046  \n","Epoch: [3][49000/77277] Elapsed 159m 53s (remain 92m 15s) Loss: 0.1416(0.1187) Grad: 9.6604  LR: 0.00000045  \n","Epoch: [3][49500/77277] Elapsed 161m 31s (remain 90m 38s) Loss: 0.0104(0.1186) Grad: 1.1380  LR: 0.00000043  \n","Epoch: [3][50000/77277] Elapsed 163m 9s (remain 89m 0s) Loss: 0.2838(0.1186) Grad: 7.0485  LR: 0.00000042  \n","Epoch: [3][50500/77277] Elapsed 164m 47s (remain 87m 22s) Loss: 0.0185(0.1185) Grad: 1.3344  LR: 0.00000040  \n","Epoch: [3][51000/77277] Elapsed 166m 25s (remain 85m 44s) Loss: 0.1838(0.1185) Grad: 11.6739  LR: 0.00000039  \n","Epoch: [3][51500/77277] Elapsed 168m 3s (remain 84m 6s) Loss: 0.1237(0.1184) Grad: 3.3779  LR: 0.00000037  \n","Epoch: [3][52000/77277] Elapsed 169m 41s (remain 82m 28s) Loss: 0.0127(0.1184) Grad: 1.3177  LR: 0.00000036  \n","Epoch: [3][52500/77277] Elapsed 171m 19s (remain 80m 50s) Loss: 0.2116(0.1183) Grad: 4.4246  LR: 0.00000034  \n","Epoch: [3][53000/77277] Elapsed 172m 57s (remain 79m 13s) Loss: 0.0056(0.1184) Grad: 0.3354  LR: 0.00000033  \n","Epoch: [3][53500/77277] Elapsed 174m 35s (remain 77m 35s) Loss: 0.0821(0.1184) Grad: 2.3193  LR: 0.00000032  \n","Epoch: [3][54000/77277] Elapsed 176m 13s (remain 75m 57s) Loss: 0.0195(0.1183) Grad: 1.0229  LR: 0.00000030  \n","Epoch: [3][54500/77277] Elapsed 177m 51s (remain 74m 19s) Loss: 0.1630(0.1183) Grad: 7.0733  LR: 0.00000029  \n","Epoch: [3][55000/77277] Elapsed 179m 29s (remain 72m 41s) Loss: 0.0124(0.1182) Grad: 1.4056  LR: 0.00000028  \n","Epoch: [3][55500/77277] Elapsed 181m 7s (remain 71m 3s) Loss: 0.3135(0.1183) Grad: 7.2512  LR: 0.00000027  \n","Epoch: [3][56000/77277] Elapsed 182m 45s (remain 69m 25s) Loss: 0.2292(0.1182) Grad: 10.8431  LR: 0.00000025  \n","Epoch: [3][56500/77277] Elapsed 184m 23s (remain 67m 48s) Loss: 0.1512(0.1182) Grad: 6.3602  LR: 0.00000024  \n","Epoch: [3][57000/77277] Elapsed 186m 1s (remain 66m 10s) Loss: 0.1426(0.1182) Grad: 6.5789  LR: 0.00000023  \n","Epoch: [3][57500/77277] Elapsed 187m 39s (remain 64m 32s) Loss: 0.1032(0.1182) Grad: 6.7685  LR: 0.00000022  \n","Epoch: [3][58000/77277] Elapsed 189m 17s (remain 62m 54s) Loss: 0.0705(0.1181) Grad: 4.5790  LR: 0.00000021  \n","Epoch: [3][58500/77277] Elapsed 190m 55s (remain 61m 16s) Loss: 0.1183(0.1181) Grad: 5.5872  LR: 0.00000020  \n","Epoch: [3][59000/77277] Elapsed 192m 33s (remain 59m 38s) Loss: 0.1113(0.1181) Grad: 5.7494  LR: 0.00000019  \n","Epoch: [3][59500/77277] Elapsed 194m 11s (remain 58m 0s) Loss: 0.0020(0.1180) Grad: 0.1467  LR: 0.00000018  \n","Epoch: [3][60000/77277] Elapsed 195m 49s (remain 56m 22s) Loss: 0.0339(0.1180) Grad: 3.2439  LR: 0.00000017  \n","Epoch: [3][60500/77277] Elapsed 197m 27s (remain 54m 45s) Loss: 0.0779(0.1179) Grad: 5.7376  LR: 0.00000016  \n","Epoch: [3][61000/77277] Elapsed 199m 5s (remain 53m 7s) Loss: 0.2347(0.1180) Grad: 4.2524  LR: 0.00000015  \n","Epoch: [3][61500/77277] Elapsed 200m 43s (remain 51m 29s) Loss: 0.3025(0.1180) Grad: 5.7436  LR: 0.00000014  \n","Epoch: [3][62000/77277] Elapsed 202m 21s (remain 49m 51s) Loss: 0.0263(0.1180) Grad: 2.2719  LR: 0.00000013  \n","Epoch: [3][62500/77277] Elapsed 203m 59s (remain 48m 13s) Loss: 0.0114(0.1180) Grad: 1.9805  LR: 0.00000012  \n","Epoch: [3][63000/77277] Elapsed 205m 37s (remain 46m 35s) Loss: 0.2031(0.1179) Grad: 4.8522  LR: 0.00000012  \n","Epoch: [3][63500/77277] Elapsed 207m 15s (remain 44m 57s) Loss: 0.1433(0.1179) Grad: 4.0436  LR: 0.00000011  \n","Epoch: [3][64000/77277] Elapsed 208m 53s (remain 43m 19s) Loss: 0.0264(0.1179) Grad: 4.3483  LR: 0.00000010  \n","Epoch: [3][64500/77277] Elapsed 210m 31s (remain 41m 42s) Loss: 0.1130(0.1179) Grad: 2.4732  LR: 0.00000009  \n","Epoch: [3][65000/77277] Elapsed 212m 9s (remain 40m 4s) Loss: 0.0153(0.1179) Grad: 0.5956  LR: 0.00000009  \n","Epoch: [3][65500/77277] Elapsed 213m 47s (remain 38m 26s) Loss: 0.1222(0.1179) Grad: 3.9781  LR: 0.00000008  \n","Epoch: [3][66000/77277] Elapsed 215m 25s (remain 36m 48s) Loss: 0.0595(0.1179) Grad: 5.4214  LR: 0.00000007  \n","Epoch: [3][66500/77277] Elapsed 217m 3s (remain 35m 10s) Loss: 0.1552(0.1178) Grad: 6.1353  LR: 0.00000007  \n","Epoch: [3][67000/77277] Elapsed 218m 41s (remain 33m 32s) Loss: 0.5132(0.1179) Grad: 16.0653  LR: 0.00000006  \n","Epoch: [3][67500/77277] Elapsed 220m 19s (remain 31m 54s) Loss: 0.1000(0.1178) Grad: 5.6512  LR: 0.00000005  \n","Epoch: [3][68000/77277] Elapsed 221m 57s (remain 30m 16s) Loss: 0.2437(0.1179) Grad: 5.8586  LR: 0.00000005  \n","Epoch: [3][68500/77277] Elapsed 223m 35s (remain 28m 38s) Loss: 0.0212(0.1178) Grad: 1.3960  LR: 0.00000004  \n","Epoch: [3][69000/77277] Elapsed 225m 13s (remain 27m 0s) Loss: 0.2828(0.1178) Grad: 6.5454  LR: 0.00000004  \n","Epoch: [3][69500/77277] Elapsed 226m 51s (remain 25m 22s) Loss: 0.0168(0.1177) Grad: 0.9447  LR: 0.00000003  \n","Epoch: [3][70000/77277] Elapsed 228m 29s (remain 23m 44s) Loss: 0.1654(0.1177) Grad: 7.1390  LR: 0.00000003  \n","Epoch: [3][70500/77277] Elapsed 230m 7s (remain 22m 7s) Loss: 0.0173(0.1177) Grad: 1.4197  LR: 0.00000003  \n","Epoch: [3][71000/77277] Elapsed 231m 45s (remain 20m 29s) Loss: 0.1177(0.1177) Grad: 5.7971  LR: 0.00000002  \n","Epoch: [3][71500/77277] Elapsed 233m 23s (remain 18m 51s) Loss: 0.3778(0.1177) Grad: 13.4717  LR: 0.00000002  \n","Epoch: [3][72000/77277] Elapsed 235m 1s (remain 17m 13s) Loss: 0.3101(0.1177) Grad: 13.0170  LR: 0.00000002  \n","Epoch: [3][72500/77277] Elapsed 236m 39s (remain 15m 35s) Loss: 0.1256(0.1177) Grad: 10.6136  LR: 0.00000001  \n","Epoch: [3][73000/77277] Elapsed 238m 17s (remain 13m 57s) Loss: 0.2603(0.1177) Grad: 11.9534  LR: 0.00000001  \n","Epoch: [3][73500/77277] Elapsed 239m 55s (remain 12m 19s) Loss: 0.0627(0.1177) Grad: 3.1347  LR: 0.00000001  \n","Epoch: [3][74000/77277] Elapsed 241m 33s (remain 10m 41s) Loss: 0.0834(0.1176) Grad: 4.9261  LR: 0.00000001  \n","Epoch: [3][74500/77277] Elapsed 243m 11s (remain 9m 3s) Loss: 0.0834(0.1176) Grad: 4.9029  LR: 0.00000000  \n","Epoch: [3][75000/77277] Elapsed 244m 50s (remain 7m 25s) Loss: 0.1448(0.1176) Grad: 5.8721  LR: 0.00000000  \n","Epoch: [3][75500/77277] Elapsed 246m 28s (remain 5m 47s) Loss: 0.0910(0.1175) Grad: 4.2035  LR: 0.00000000  \n","Epoch: [3][76000/77277] Elapsed 248m 6s (remain 4m 9s) Loss: 0.0729(0.1175) Grad: 1.9508  LR: 0.00000000  \n","Epoch: [3][76500/77277] Elapsed 249m 44s (remain 2m 31s) Loss: 0.0107(0.1174) Grad: 0.6542  LR: 0.00000000  \n","Epoch: [3][77000/77277] Elapsed 251m 22s (remain 0m 54s) Loss: 0.0205(0.1174) Grad: 2.3923  LR: 0.00000000  \n","Epoch: [3][77276/77277] Elapsed 252m 16s (remain 0m 0s) Loss: 0.0368(0.1174) Grad: 1.2480  LR: 0.00000000  \n","EVAL: [0/19225] Elapsed 0m 1s (remain 503m 45s) Loss: 0.3596(0.3596) \n","EVAL: [500/19225] Elapsed 1m 23s (remain 51m 48s) Loss: 0.2436(0.3355) \n","EVAL: [1000/19225] Elapsed 2m 46s (remain 50m 37s) Loss: 0.0108(0.2710) \n","EVAL: [1500/19225] Elapsed 4m 6s (remain 48m 35s) Loss: 0.1808(0.2470) \n","EVAL: [2000/19225] Elapsed 5m 30s (remain 47m 23s) Loss: 0.4721(0.2393) \n","EVAL: [2500/19225] Elapsed 6m 55s (remain 46m 18s) Loss: 0.2241(0.2252) \n","EVAL: [3000/19225] Elapsed 8m 23s (remain 45m 21s) Loss: 0.6415(0.2138) \n","EVAL: [3500/19225] Elapsed 9m 53s (remain 44m 27s) Loss: 0.3696(0.2095) \n","EVAL: [4000/19225] Elapsed 11m 24s (remain 43m 24s) Loss: 0.5762(0.2014) \n","EVAL: [4500/19225] Elapsed 12m 48s (remain 41m 52s) Loss: 0.3893(0.1966) \n","EVAL: [5000/19225] Elapsed 14m 13s (remain 40m 28s) Loss: 0.2746(0.1926) \n","EVAL: [5500/19225] Elapsed 15m 42s (remain 39m 12s) Loss: 0.4832(0.1903) \n","EVAL: [6000/19225] Elapsed 17m 10s (remain 37m 51s) Loss: 0.0034(0.1892) \n","EVAL: [6500/19225] Elapsed 18m 46s (remain 36m 44s) Loss: 0.0392(0.1850) \n","EVAL: [7000/19225] Elapsed 20m 20s (remain 35m 31s) Loss: 0.1273(0.1823) \n","EVAL: [7500/19225] Elapsed 21m 53s (remain 34m 13s) Loss: 0.1179(0.1788) \n","EVAL: [8000/19225] Elapsed 23m 24s (remain 32m 50s) Loss: 0.2224(0.1770) \n","EVAL: [8500/19225] Elapsed 24m 54s (remain 31m 25s) Loss: 0.0222(0.1758) \n","EVAL: [9000/19225] Elapsed 26m 20s (remain 29m 55s) Loss: 0.0063(0.1739) \n","EVAL: [9500/19225] Elapsed 27m 56s (remain 28m 35s) Loss: 0.0003(0.1727) \n","EVAL: [10000/19225] Elapsed 29m 27s (remain 27m 10s) Loss: 0.0047(0.1721) \n","EVAL: [10500/19225] Elapsed 31m 1s (remain 25m 46s) Loss: 0.3361(0.1716) \n","EVAL: [11000/19225] Elapsed 32m 37s (remain 24m 23s) Loss: 0.0005(0.1708) \n","EVAL: [11500/19225] Elapsed 34m 13s (remain 22m 58s) Loss: 0.5326(0.1703) \n","EVAL: [12000/19225] Elapsed 35m 50s (remain 21m 34s) Loss: 0.1038(0.1701) \n","EVAL: [12500/19225] Elapsed 37m 28s (remain 20m 9s) Loss: 0.1014(0.1698) \n","EVAL: [13000/19225] Elapsed 39m 7s (remain 18m 43s) Loss: 0.0011(0.1690) \n","EVAL: [13500/19225] Elapsed 40m 46s (remain 17m 17s) Loss: 0.0110(0.1686) \n","EVAL: [14000/19225] Elapsed 42m 22s (remain 15m 48s) Loss: 0.0008(0.1695) \n","EVAL: [14500/19225] Elapsed 44m 4s (remain 14m 21s) Loss: 0.0208(0.1695) \n","EVAL: [15000/19225] Elapsed 45m 46s (remain 12m 53s) Loss: 1.0434(0.1697) \n","EVAL: [15500/19225] Elapsed 47m 25s (remain 11m 23s) Loss: 0.1138(0.1700) \n","EVAL: [16000/19225] Elapsed 49m 6s (remain 9m 53s) Loss: 0.0217(0.1700) \n","EVAL: [16500/19225] Elapsed 50m 47s (remain 8m 23s) Loss: 0.0367(0.1703) \n","EVAL: [17000/19225] Elapsed 52m 28s (remain 6m 51s) Loss: 0.5937(0.1710) \n","EVAL: [17500/19225] Elapsed 54m 9s (remain 5m 20s) Loss: 0.0857(0.1715) \n","EVAL: [18000/19225] Elapsed 55m 53s (remain 3m 48s) Loss: 0.1935(0.1723) \n","EVAL: [18500/19225] Elapsed 57m 37s (remain 2m 15s) Loss: 0.2743(0.1741) \n","EVAL: [19000/19225] Elapsed 59m 25s (remain 0m 42s) Loss: 0.0795(0.1764) \n","EVAL: [19224/19225] Elapsed 60m 21s (remain 0m 0s) Loss: 0.1623(0.1786) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - Save Best Score: 0.6107 Model\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 11, in <module>\n","    _oof_df = train_loop(train, correlations, fold, CFG)\n","  File \"<ipython-input-17-02c5098fcfa5>\", line 125, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","Message: 'Epoch 3 - Save Best Score: 0.6107 Model'\n","Arguments: ()\n","INFO:__main__:Epoch 3 - Save Best Score: 0.6107 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 - avg_train_loss: 0.1174  avg_val_loss: 0.1786  time: 18858s\n","Epoch 3 - Score: 0.6107 - Threshold: 0.03000\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 13, in <module>\n","    LOGGER.info(f\"========== fold: {fold} result ==========\")\n","Message: '========== fold: 0 result =========='\n","Arguments: ()\n","INFO:__main__:========== fold: 0 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["Our CV score is 0.6107 using a threshold of 0.030000000000000002\n"]},{"output_type":"stream","name":"stderr","text":["Our CV score is 0.6107 using a threshold of 0.030000000000000002\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 14, in <module>\n","    get_result(_oof_df)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 5, in get_result\n","    LOGGER.info(f'Our CV score is {best_score} using a threshold of {best_threshold}')\n","Message: 'Our CV score is 0.6107 using a threshold of 0.030000000000000002'\n","Arguments: ()\n","INFO:__main__:Our CV score is 0.6107 using a threshold of 0.030000000000000002\n","========== CV ==========\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 16, in <module>\n","    LOGGER.info(f\"========== CV ==========\")\n","Message: '========== CV =========='\n","Arguments: ()\n","INFO:__main__:========== CV ==========\n","Our CV score is 0.6107 using a threshold of 0.030000000000000002\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1089, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.8/logging/__init__.py\", line 1069, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 821, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 782, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 543, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.8/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2854, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3057, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 17, in <module>\n","    get_result(oof_df)\n","  File \"<ipython-input-18-0c82a1d54aa9>\", line 5, in get_result\n","    LOGGER.info(f'Our CV score is {best_score} using a threshold of {best_threshold}')\n","Message: 'Our CV score is 0.6107 using a threshold of 0.030000000000000002'\n","Arguments: ()\n","INFO:__main__:Our CV score is 0.6107 using a threshold of 0.030000000000000002\n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        best_score, best_threshold = get_best_threshold(oof_df, oof_df.pred.values, correlations)\n","        LOGGER.info(f'Our CV score is {best_score} using a threshold of {best_threshold}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_folds):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, correlations, fold, CFG)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(os.path.join(OUTPUT_MODELS_EXP,'oof_df.pkl'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RnF2gYXsouwX"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPMijQttF5EmFq35FJ10MBq"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}